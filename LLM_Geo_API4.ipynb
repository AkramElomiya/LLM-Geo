{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bf073e47-9e79-41d3-bc84-500590ad2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DATA_LOCATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# add the API documentation to DATA_LOCATION\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, path \u001b[38;5;129;01min\u001b[39;00m API_DOC_LOCATION:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     61\u001b[0m         docs \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines(f)\n\u001b[0;32m     62\u001b[0m     DATA_LOCATIONS \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe documentation is: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m docs\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt'"
     ]
    }
   ],
   "source": [
    "# Case 1: population living near hazardous waster\n",
    "'''\n",
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight the borders of tracts that have hazardous waste facilities.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "'''\n",
    "\n",
    "# Case 2: mobility data retrieval and visulization\n",
    "\"\"\"\n",
    "TASK = r'''\n",
    "1) Show the monthly change rates of each administrative regions in a France map. Each month is a sub-map in a map matrix. The base of the change rate is January 2020. \n",
    "2) Draw a line chart to show the monthly change rate trends of all administrative regeions.\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "                  \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip.\" + \\\n",
    "                  \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "                  \"REST API url with parameters for mobility data access:\" + \\\n",
    "                  \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "                  \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "                  \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code, France administrative regions start with 'FRA'.\",\n",
    "                 ]\n",
    "\n",
    "# Bug: \n",
    "# base_month =  \"2020-01\" # wrong: pd.to_datetime(\"2020-01\")\n",
    "# print(region_monthly[region_monthly['month_year'] == base_month])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Case 3: mobility data retrieval and visulization\n",
    "# TASK = r\"\"\"1) Find out the Autism service providers' addresses or location from their website. The address usually listed in the homepage, 'about' or 'contact' page. The latter two pages usually contain 'about' or 'contact' in links embedded in the homepage.\n",
    "# 2) A provider may have multiple service address. If cannot find the address, simply return an empty text, DO NOT make up fake addresses. \n",
    "# 3) You need to send webpage text ChatGPT to extract address. Use this pre-written function your designed detailed prompt to get response from ChatGPT: helper.get_LLM_reply(prompt=your_prompt_with_webpage_text, model=r\"gpt-4\",). Use this statement to extract content from the returned response: response['choices'][0]['message']['content']. Let ChatGPT reply in json format as {'address': extracted_address}.  DO NOT reuturn explaination or conversation, return the address or empty text only. \n",
    "# 4) Save the extracted addresses as \"Address\" column, together with the given 'Provider' and 'Web Site' columns. If there are multile addresses for a provider, each address is a row in the CSV file.\n",
    "# \"\"\"\n",
    "\n",
    "# DATA_LOCATIONS = [\"Autism service provider webpage file location: E:\\Research\\LLM-Geo\\Address_extraction\\ACE_providers_AGIS.csv. The 'Web Site' column is the URL, the 'Provider' column is the provider name.\",                  \n",
    "#                  ]\n",
    "\n",
    "# Case 4: COVID-19 prevalence \n",
    "TASK = r\"\"\"1) Draw map matrix of South Carolina counties' monthly COVID-19 infection ratio with a weekly smooth in 2021.\n",
    "2) the infection ratio = (infection of this month / county popultion).\n",
    "\"\"\"\n",
    "\n",
    "API_DOC_LOCATION = [(1, r'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt')] \n",
    "# [(Input_data_index, API_cocumentation_path)]\n",
    "\n",
    "DATA_LOCATIONS = [\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01),county,state,fips,cases,deaths\",                  \n",
    "                  \"Population data: use Python library CensusData to obtain data. \",\n",
    "                 ]\n",
    "\n",
    "# add the API documentation to DATA_LOCATION\n",
    "for idx, path in API_DOC_LOCATION:\n",
    "    with open(path, 'r') as f:\n",
    "        docs = f.readlines(f)\n",
    "    DATA_LOCATIONS += \"The documentation is: \\n\" + docs\n",
    "\n",
    "\n",
    "# https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/Address_extraction/ACE_providers_AGIS.csv\n",
    "\n",
    "# TASK = r'''1)Retrieve the data from the REST API and plot the intra_movement column of the returned data as line chart to show the temporal trend of all states. \n",
    "# 2) plot the temporal trend of the movement for each state. Each state figure will be sub figure in the plot. The plot has 5 columns. In addition, please add a weekly smoothed line to each sub plot, and change the line color to orange.\n",
    "# 3) Using the REST API with date range from 01/01/2020 to 12/31/2020 to analyze the movement reduction rate for each state during two periods: the first period is 01/01/2020-02/29/2020, second period is 03/01/2020 to 04/30/2020. Please find out the reduction rate for each state during the two periods, and create a table to report the result with two columns: state name, reduction rate, sorted by reduction rate.\n",
    "# '''\n",
    "# '''\n",
    "# DATA_LOCATIONS = [\"REST API url with parameters for data access: http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=us_state&begin=01/01/2020&end=12/31/2020; The response is in CSV format. There are three columns in the response: place,date,intra_movement; place refers to the state name.\"\n",
    "#                  ]\n",
    "# '''\n",
    "# 3) Show the administrative region name in the map and chart.\n",
    "# \n",
    "# task_name ='Resident_at_risk_counting'\n",
    "# task_name ='France_mobility_changes_2020'  \n",
    "task_name ='Address_extraction'  \n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# 1. Load Autism service provider CSV file\n",
      "G.add_node(\"provider_csv_path\", node_type=\"data\", data_path=\"E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\ACE_providers_AGIS.csv\", description=\"Autism service provider CSV file\")\n",
      "G.add_node(\"load_provider_csv\", node_type=\"operation\", description=\"Load Autism service provider CSV file\")\n",
      "G.add_edge(\"provider_csv_path\", \"load_provider_csv\")\n",
      "\n",
      "# 2. Extract address using helper function and ChatGPT\n",
      "G.add_node(\"provider_data\", node_type=\"data\", description=\"Autism service providers and their website URLs\")\n",
      "G.add_edge(\"load_provider_csv\", \"provider_data\")\n",
      "G.add_node(\"provider_addresses\", node_type=\"data\", description=\"Extracted Autism service provider addresses\")\n",
      "G.add_node(\"extract_address\", node_type=\"operation\", description=\"Extract Autism service provider addresses from webpages using ChatGPT\")\n",
      "G.add_edge(\"provider_data\", \"extract_address\")\n",
      "G.add_edge(\"extract_address\", \"provider_addresses\")\n",
      "\n",
      "# 3. Save extracted address into CSV\n",
      "G.add_node(\"combined_data\", node_type=\"data\", description=\"Autism service provider data combined with addresses\")\n",
      "G.add_node(\"join_addresses\", node_type=\"operation\", description=\"Join extracted addresses to the provider data\")\n",
      "G.add_edge(\"provider_data\", \"join_addresses\")\n",
      "G.add_edge(\"provider_addresses\", \"join_addresses\")\n",
      "G.add_edge(\"join_addresses\", \"combined_data\")\n",
      "\n",
      "G.add_node(\"save_to_csv\", node_type=\"operation\", description=\"Save combined provider data to CSV\")\n",
      "G.add_edge(\"combined_data\", \"save_to_csv\")\n",
      "\n",
      "# Save graph to GraphML\n",
      "nx.write_graphml(G, \"E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\Address_extraction.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Research\\LLM-Geo\\Address_extraction.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"E:\\Research\\LLM-Geo\\Address_extraction.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23dd544e590>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "italic-appearance",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(r'F:\\Research\\LLM-Geo\\Resident_at_risk_counting\\Resident_at_risk_counting.pkl', 'rb') as f:\n",
    "#     solution = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 4, load_provider_csv\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "2 / 4, extract_address\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "3 / 4, join_addresses\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "4 / 4, save_to_csv\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "\n",
    "# all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "# print(\"All operation code: \\n\")\n",
    "# print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cd1a4f35-689d-45c0-a66a-568868771de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "\n",
      "def load_provider_csv(provider_csv_path='E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\ACE_providers_AGIS.csv'):\n",
      "    # Description: Load Autism service provider CSV file\n",
      "    # provider_csv_path: The path to the Autism service provider CSV file\n",
      "    provider_data = pd.read_csv(provider_csv_path)\n",
      "    return provider_data\n",
      "import pandas as pd\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "from tqdm import tqdm\n",
      "import helper\n",
      "\n",
      "def extract_address(provider_data):\n",
      "    \"\"\"\n",
      "    Description: Extract Autism service provider addresses from webpages using ChatGPT\n",
      "    provider_data: A DataFrame containing provider names and their website URLs\n",
      "    Return: A DataFrame containing provider names, website URLs, and extracted addresses\n",
      "    \"\"\"\n",
      "    \n",
      "    def get_address_from_web_page(url):\n",
      "        try:\n",
      "            r = requests.get(url)\n",
      "            r.raise_for_status()\n",
      "            soup = BeautifulSoup(r.text, 'html.parser')\n",
      "\n",
      "            possible_links = [url] + [link.get('href') for link in soup.find_all('a') if 'about' in link.get('href', '').lower() or 'contact' in link.get('href', '').lower()]\n",
      "\n",
      "            for link in possible_links:\n",
      "                soup2 = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
      "                prompt = 'Extract the address of the Autism service provider from the following web page text: ' + soup2.get_text()\n",
      "                response = helper.get_LLM_reply(prompt=prompt, model=\"gpt-4\",)\n",
      "\n",
      "                extracted_address = response['choices'][0]['message']['content']\n",
      "                if extracted_address:\n",
      "                    return extracted_address\n",
      "\n",
      "        except Exception as e:\n",
      "            print(f\"Error while extracting address from {url}: {e}\")\n",
      "            return ''\n",
      "\n",
      "    provider_addresses = []\n",
      "\n",
      "    for idx, row in tqdm(provider_data.iterrows(), total=len(provider_data)):\n",
      "        provider_name = row['Provider']\n",
      "        website_url = row['Web Site']\n",
      "        \n",
      "        extracted_address = get_address_from_web_page(website_url)\n",
      "        \n",
      "        if extracted_address:\n",
      "            provider_addresses.append({'Provider': provider_name, 'Web Site': website_url, 'Address': extracted_address})\n",
      "    \n",
      "    return pd.DataFrame(provider_addresses)\n",
      "import pandas as pd\n",
      "\n",
      "def join_addresses(provider_data, provider_addresses):\n",
      "    \"\"\"\n",
      "    Description: Join extracted addresses to the provider data\n",
      "    \n",
      "    provider_data: A DataFrame containing provider names and their website URLs\n",
      "    provider_addresses: A DataFrame containing provider names, website URLs, and extracted addresses\n",
      "    Return: A DataFrame containing provider names, website URLs, and addresses after joining the input DataFrames\n",
      "    \"\"\"\n",
      "\n",
      "    combined_data = pd.merge(provider_data, provider_addresses, on=['Provider', 'Web Site'], how='left')\n",
      "    \n",
      "    return combined_data\n",
      "import pandas as pd\n",
      "\n",
      "def save_to_csv(combined_data):\n",
      "    \"\"\"\n",
      "    Description: Save combined provider data to CSV\n",
      "    combined_data: A DataFrame containing provider names, website URLs, and addresses after joining the input DataFrames\n",
      "    Return: None\n",
      "    \"\"\"\n",
      "    \n",
      "    combined_data.to_csv('E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\combined_provider_addresses.csv', index=False)\n",
      "    return\n"
     ]
    }
   ],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "exec(all_operation_code_str)\n",
    "print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "import pandas as pd\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "from tqdm import tqdm\n",
      "import helper\n",
      "\n",
      "def load_provider_csv(provider_csv_path='E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\ACE_providers_AGIS.csv'):\n",
      "    provider_data = pd.read_csv(provider_csv_path)\n",
      "    return provider_data\n",
      "\n",
      "def extract_address(provider_data):\n",
      "    \n",
      "    def get_address_from_web_page(url):\n",
      "        try:\n",
      "            r = requests.get(url)\n",
      "            r.raise_for_status()\n",
      "            soup = BeautifulSoup(r.text, 'html.parser')\n",
      "\n",
      "            possible_links = [url] + [link.get('href') for link in soup.find_all('a') if 'about' in link.get('href', '').lower() or 'contact' in link.get('href', '').lower()]\n",
      "\n",
      "            for link in possible_links:\n",
      "                soup2 = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
      "                prompt = 'Extract the address of the Autism service provider from the following web page text: ' + soup2.get_text()\n",
      "                response = helper.get_LLM_reply(prompt=prompt, model=\"gpt-4\",)\n",
      "\n",
      "                extracted_address = response['choices'][0]['message']['content']\n",
      "                if extracted_address:\n",
      "                    return extracted_address\n",
      "\n",
      "        except Exception as e:\n",
      "            print(f\"Error while extracting address from {url}: {e}\")\n",
      "            return ''\n",
      "\n",
      "    provider_addresses = []\n",
      "\n",
      "    for idx, row in tqdm(provider_data.iterrows(), total=len(provider_data)):\n",
      "        provider_name = row['Provider']\n",
      "        website_url = row['Web Site']\n",
      "        \n",
      "        extracted_address = get_address_from_web_page(website_url)\n",
      "        \n",
      "        if extracted_address:\n",
      "            provider_addresses.append({'Provider': provider_name, 'Web Site': website_url, 'Address': extracted_address})\n",
      "    \n",
      "    return pd.DataFrame(provider_addresses)\n",
      "\n",
      "def join_addresses(provider_data, provider_addresses):\n",
      "    combined_data = pd.merge(provider_data, provider_addresses, on=['Provider', 'Web Site'], how='left')\n",
      "    return combined_data\n",
      "\n",
      "def save_to_csv(combined_data):\n",
      "    combined_data.to_csv('E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\combined_provider_addresses.csv', index=False)\n",
      "    return\n",
      "\n",
      "# Main execution flow\n",
      "provider_data = load_provider_csv()\n",
      "provider_addresses = extract_address(provider_data)\n",
      "combined_data = join_addresses(provider_data, provider_addresses)\n",
      "save_to_csv(combined_data)\n"
     ]
    }
   ],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "# print(\"Assembly code: \\n\")\n",
    "# print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "from tqdm import tqdm\n",
      "import helper\n",
      "\n",
      "def load_provider_csv(provider_csv_path='E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\ACE_providers_AGIS.csv'):\n",
      "    provider_data = pd.read_csv(provider_csv_path)\n",
      "    return provider_data\n",
      "\n",
      "def extract_address(provider_data):\n",
      "    \n",
      "    def get_address_from_web_page(url):\n",
      "        try:\n",
      "            r = requests.get(url)\n",
      "            r.raise_for_status()\n",
      "            soup = BeautifulSoup(r.text, 'html.parser')\n",
      "\n",
      "            possible_links = [url] + [link.get('href') for link in soup.find_all('a') if 'about' in link.get('href', '').lower() or 'contact' in link.get('href', '').lower()]\n",
      "\n",
      "            for link in possible_links:\n",
      "                soup2 = BeautifulSoup(requests.get(link).text, 'html.parser')\n",
      "                prompt = 'Extract the address of the Autism service provider from the following web page text: ' + soup2.get_text()\n",
      "                response = helper.get_LLM_reply(prompt=prompt, model=\"gpt-4\",)\n",
      "\n",
      "                extracted_address = response['choices'][0]['message']['content']\n",
      "                if extracted_address:\n",
      "                    return extracted_address\n",
      "\n",
      "        except Exception as e:\n",
      "            print(f\"Error while extracting address from {url}: {e}\")\n",
      "            return ''\n",
      "\n",
      "    provider_addresses = []\n",
      "\n",
      "    for idx, row in tqdm(provider_data.iterrows(), total=len(provider_data)):\n",
      "        provider_name = row['Provider']\n",
      "        website_url = row['Web Site']\n",
      "        \n",
      "        extracted_address = get_address_from_web_page(website_url)\n",
      "        \n",
      "        if extracted_address:\n",
      "            provider_addresses.append({'Provider': provider_name, 'Web Site': website_url, 'Address': extracted_address})\n",
      "    \n",
      "    return pd.DataFrame(provider_addresses)\n",
      "\n",
      "def join_addresses(provider_data, provider_addresses):\n",
      "    combined_data = pd.merge(provider_data, provider_addresses, on=['Provider', 'Web Site'], how='left')\n",
      "    return combined_data\n",
      "\n",
      "def save_to_csv(combined_data):\n",
      "    combined_data.to_csv('E:\\\\Research\\\\LLM-Geo\\\\Address_extraction\\\\combined_provider_addresses.csv', index=False)\n",
      "    return\n",
      "\n",
      "# Main execution flow\n",
      "provider_data = load_provider_csv()\n",
      "provider_addresses = extract_address(provider_data)\n",
      "combined_data = join_addresses(provider_data, provider_addresses)\n",
      "save_to_csv(combined_data)\n"
     ]
    }
   ],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "90365390-4b0a-4164-8b25-5179d13da5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:06<00:58,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:20<01:26, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:20<00:42,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while extracting address from http://buildingblocksbehavioralservices.com: 403 Client Error: Forbidden for url: http://buildingblocksbehavioralservices.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:21<00:23,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while extracting address from https://cbacares.com/: 403 Client Error: Forbidden for url: https://cbacares.com/\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:48<01:00, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:48<00:33,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while extracting address from http://www.autismnj.org: 403 Client Error: Forbidden for url: https://www.autismnj.org/\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:55<00:23,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:02<00:14,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:08<00:07,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:08<00:00,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while extracting address from https://www.breakingbarrierstherapy.com: 403 Client Error: Forbidden for url: https://www.breakingbarrierstherapy.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0052ec70-cdab-4323-a909-35d48866982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Web Site</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behavior Change and Associates</td>\n",
       "      <td>http://www.behaviorchange.com</td>\n",
       "      <td>Behavior Change &amp; Associates\\n160 East Lake Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bluestem Center for Autism</td>\n",
       "      <td>http://www.bluestemcenterforautism.com</td>\n",
       "      <td>Rochester:\\n124 Elton Hills Ln NW\\nRochester, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Building Blocks Behavioral Services</td>\n",
       "      <td>http://buildingblocksbehavioralservices.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Behavior Analysis</td>\n",
       "      <td>https://cbacares.com/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlphaBee, Inc</td>\n",
       "      <td>http://www.alphabee.com/</td>\n",
       "      <td>The web page text does not provide a specific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Autism New Jersey</td>\n",
       "      <td>http://www.autismnj.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BGF Performance Systems, LLC</td>\n",
       "      <td>http://www.bgftherapy.com</td>\n",
       "      <td>BGF Children's Therapy\\n6430 N. Central Ave, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Behavioral and Educational Strategies and Trai...</td>\n",
       "      <td>http://www.bestforautism.com/</td>\n",
       "      <td>2630 West Rumble Road, Modesto, CA. 95350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beyond Expectations, Inc.</td>\n",
       "      <td>http://www.beitherapy.com</td>\n",
       "      <td>Address: 15 10th Avenue Shalimar Florida, 32579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Breaking Barriers Therapy Services</td>\n",
       "      <td>https://www.breakingbarrierstherapy.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Provider  \\\n",
       "0                     Behavior Change and Associates   \n",
       "1                         Bluestem Center for Autism   \n",
       "2                Building Blocks Behavioral Services   \n",
       "3                         Clinical Behavior Analysis   \n",
       "4                                      AlphaBee, Inc   \n",
       "5                                  Autism New Jersey   \n",
       "6                       BGF Performance Systems, LLC   \n",
       "7  Behavioral and Educational Strategies and Trai...   \n",
       "8                          Beyond Expectations, Inc.   \n",
       "9                 Breaking Barriers Therapy Services   \n",
       "\n",
       "                                      Web Site  \\\n",
       "0                http://www.behaviorchange.com   \n",
       "1       http://www.bluestemcenterforautism.com   \n",
       "2  http://buildingblocksbehavioralservices.com   \n",
       "3                        https://cbacares.com/   \n",
       "4                     http://www.alphabee.com/   \n",
       "5                      http://www.autismnj.org   \n",
       "6                    http://www.bgftherapy.com   \n",
       "7                http://www.bestforautism.com/   \n",
       "8                    http://www.beitherapy.com   \n",
       "9      https://www.breakingbarrierstherapy.com   \n",
       "\n",
       "                                             Address  \n",
       "0  Behavior Change & Associates\\n160 East Lake Br...  \n",
       "1  Rochester:\\n124 Elton Hills Ln NW\\nRochester, ...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  The web page text does not provide a specific ...  \n",
       "5                                                NaN  \n",
       "6  BGF Children's Therapy\\n6430 N. Central Ave, 6...  \n",
       "7          2630 West Rumble Road, Modesto, CA. 95350  \n",
       "8    Address: 15 10th Avenue Shalimar Florida, 32579  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "04ad14dc-1217-4a94-8c11-166efdf5302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Behavior Change & Associates\\n160 East Lake Br...\n",
      "1    Rochester:\\n124 Elton Hills Ln NW\\nRochester, ...\n",
      "2    The address of the Autism service provider, Al...\n",
      "3    BGF Children's Therapy\\n6430 N. Central Ave, 6...\n",
      "4    The address of the Autism service provider is:...\n",
      "5    Address of the Autism service provider:\\n\\nAdm...\n",
      "Name: Address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(provider_addresses['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0eb0cb31-cf18-4e18-8d5a-682e5f2ee340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dd034cd6-c4d0-4d85-868a-f3acc7da0fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:08<01:13,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:29<02:08, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data for Bluestem Center for Autism: HTTPSConnectionPool(host='mn.gov', port=443): Max retries exceeded with url: /autism/about-autism/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)')))\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:34<01:14, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:36<00:44,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:08<01:20, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:13<00:50, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:24<00:35, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:29<00:19,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:42<00:10, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:46<00:00, 10.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                               | 1/23 [00:02<01:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Error extracting address components for Behavior Change and Associates: not enough values to unpack (expected 4, got 1)\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                           | 2/23 [00:04<00:48,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Error extracting address components for Behavior Change and Associates: not enough values to unpack (expected 4, got 1)\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▊                                                                        | 3/23 [00:06<00:43,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got LLM reply.\n",
      "Error extracting address components for Behavior Change and Associates: not enough values to unpack (expected 4, got 1)\n",
      "Geting LLM reply...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▊                                                                        | 3/23 [00:19<02:11,  6.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[217], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m provider_n_website_columns \u001b[38;5;241m=\u001b[39m load_ACE_providers_csv()\n\u001b[0;32m      2\u001b[0m raw_addresses \u001b[38;5;241m=\u001b[39m fetch_addresses_from_websites(provider_n_website_columns)\n\u001b[1;32m----> 3\u001b[0m address_components \u001b[38;5;241m=\u001b[39m \u001b[43mextract_address_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_addresses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m save_extracted_addresses(provider_n_website_columns, address_components)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted addresses saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<string>:87\u001b[0m, in \u001b[0;36mextract_address_components\u001b[1;34m(raw_addresses)\u001b[0m\n",
      "File \u001b[1;32mE:\\Research\\LLM-Geo\\helper.py:48\u001b[0m, in \u001b[0;36mget_LLM_reply\u001b[1;34m(prompt, system_role, model, verbose)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeting LLM reply...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_role\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot LLM reply.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m _make_session()\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "provider_n_website_columns = load_ACE_providers_csv()\n",
    "raw_addresses = fetch_addresses_from_websites(provider_n_website_columns)\n",
    "address_components = extract_address_components(raw_addresses)\n",
    "output_csv = save_extracted_addresses(provider_n_website_columns, address_components)\n",
    "print(f\"Extracted addresses saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c61f4-fa4d-4456-8fc5-1759c6198ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5aac09-fb66-4d6a-978d-3be5c25d3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 2: mobility \n",
    "# import geopandas as gpd\n",
    "\n",
    "# def load_france_shp(france_shp_url=\"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip\"):\n",
    "#     \"\"\"\n",
    "#     Description: Load France administrative regions shapefile\n",
    "\n",
    "#     Args:\n",
    "#     france_shp_url (str): URL of the zipped shapefile\n",
    "\n",
    "#     Returns:\n",
    "#     france_gdf (GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "#     \"\"\"\n",
    "#     france_gdf = gpd.read_file(france_shp_url)\n",
    "#     return france_gdf\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import requests\n",
    "# from io import StringIO\n",
    "\n",
    "# def load_mobility_data(mobility_api_url=\"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020\"):\n",
    "#     \"\"\"\n",
    "#     Load COVID-19 mobility data\n",
    "\n",
    "#     mobility_api_url: REST API url for COVID-19 mobility data\n",
    "#     returns: mobility_data (dataframe): Mobility data with place, date and intra_movement values\n",
    "#     \"\"\"\n",
    "#     response = requests.get(mobility_api_url)\n",
    "#     data = StringIO(response.text)\n",
    "#     mobility_data = pd.read_csv(data)\n",
    "\n",
    "#     return mobility_data\n",
    "# def join_data(france_gdf=gpd.GeoDataFrame(), mobility_data=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Join shapefile and mobility data\n",
    "\n",
    "#     Args:\n",
    "#     france_gdf (GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "#     mobility_data (pd.DataFrame): Mobility data with place, date, and intra_movement values\n",
    "\n",
    "#     Returns:\n",
    "#     joined_data (GeoDataFrame): GeoDataFrame containing the joined shapefile and mobility data\n",
    "#     \"\"\"\n",
    "#     # Convert GID_1 column to string type without leading zeros\n",
    "#     france_gdf[\"GID_1\"] = france_gdf[\"GID_1\"].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#     # Convert place column to string type without leading zeros\n",
    "#     mobility_data[\"place\"] = mobility_data[\"place\"].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#     # Merge mobility data with shapefile based on GID_1 and place columns\n",
    "#     joined_data = france_gdf.merge(mobility_data, left_on=\"GID_1\", right_on=\"place\")\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     joined_data.drop_duplicates(subset=[\"GID_1\", \"date\"], inplace=True)\n",
    "\n",
    "#     return joined_data\n",
    "# def calc_monthly_changes(joined_data=gpd.GeoDataFrame()):\n",
    "#     \"\"\"\n",
    "#     Create monthly change rates\n",
    "    \n",
    "#     Args:\n",
    "#     joined_data (gpd.GeoDataFrame): GeoDataFrame containing the joined shapefile and mobility data\n",
    "    \n",
    "#     Returns:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "#     \"\"\"\n",
    "#     # Parse dates and create a month-year column\n",
    "#     joined_data['date'] = pd.to_datetime(joined_data['date'])\n",
    "#     joined_data['month_year'] = joined_data['date'].dt.to_period('M')\n",
    "\n",
    "#     # Calculate the sum of intra_movement for each region and month-year\n",
    "#     region_monthly = joined_data.groupby(['NAME_1', 'month_year'])['intra_movement'].sum().reset_index()\n",
    "\n",
    "#     # Calculate the changes of each month based on January 2020\n",
    "#     base_month =  \"2020-01\" # pd.to_datetime(\"2020-01\")\n",
    "#     print(region_monthly[region_monthly['month_year'] == \"2020-01\"])\n",
    "#     baseline = region_monthly[region_monthly['month_year'] == base_month].set_index('NAME_1')['intra_movement']\n",
    "#     print(baseline)\n",
    "#     region_monthly['change_rate'] = region_monthly.apply(lambda row: (row['intra_movement'] - baseline[row['NAME_1']]) / baseline[row['NAME_1']], axis=1)\n",
    "\n",
    "#     # Pivot month_year as columns to create monthly_changes DataFrame\n",
    "#     monthly_changes = region_monthly.pivot(index='NAME_1', columns='month_year', values='change_rate').reset_index()\n",
    "\n",
    "#     return monthly_changes\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def matrix_map(monthly_changes=pd.DataFrame(), france_gdf=gpd.GeoDataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Create matrix of France maps\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "#     france_gdf (gpd.GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "\n",
    "#     Returns:\n",
    "#     france_map_fig (Figure): Figure containing the matrix of France maps with monthly change rates\n",
    "#     \"\"\"\n",
    "#     # Merge monthly_changes with france_gdf\n",
    "#     france_gdf = france_gdf.merge(monthly_changes, on=\"NAME_1\")\n",
    "    \n",
    "#     # Set up plot\n",
    "#     plt.style.use('seaborn-darkgrid')\n",
    "#     france_map_fig, axs = plt.subplots(3, 4, figsize=(24, 18), sharex='col', sharey='row')\n",
    "#     france_map_fig.suptitle('Monthly change rates of each administrative region in France')\n",
    "\n",
    "#     # Iterate through columns for each month\n",
    "#     for idx, month_year in enumerate(monthly_changes.columns[1:]):\n",
    "#         row, col = divmod(idx, 4)\n",
    "        \n",
    "#         # Create subplot\n",
    "#         france_gdf.plot(column=month_year, ax=axs[row, col], legend=True, cmap='coolwarm', legend_kwds={'shrink': 0.8})\n",
    "#         axs[row, col].set_title(month_year.strftime(\"%B %Y\"))\n",
    "#         axs[row, col].set_xticks([])\n",
    "#         axs[row, col].set_yticks([])\n",
    "#         axs[row, col].set_xlabel(\"\")\n",
    "#         axs[row, col].set_ylabel(\"\")\n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    \n",
    "#     return france_map_fig\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def chart_matrix(monthly_changes=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Create chart matrix of each administrative region's line chart\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "\n",
    "#     Returns:\n",
    "#     line_chart_matrix_fig (matplotlib.figure.Figure): Figure object containing the line chart matrix\n",
    "#     \"\"\"\n",
    "#     # Set default seaborn style\n",
    "#     sns.set()\n",
    "\n",
    "#     # Prepare monthly_changes data\n",
    "#     monthly_changes_tidy = pd.melt(monthly_changes, \n",
    "#                                    id_vars=[\"NAME_1\"], \n",
    "#                                    var_name=\"month_year\", \n",
    "#                                    value_name=\"change_rate\")\n",
    "#     monthly_changes_tidy[\"month_year\"] = monthly_changes_tidy[\"month_year\"].astype(str)\n",
    "\n",
    "#     # Calculate the number of rows and columns for the line chart matrix\n",
    "#     n_regions = len(monthly_changes[\"NAME_1\"].unique())\n",
    "#     n_cols = min(4, n_regions)\n",
    "#     n_rows = (n_regions // n_cols) + (1 if (n_regions % n_cols) else 0)\n",
    "\n",
    "#     # Create the line chart matrix\n",
    "#     line_chart_matrix_fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5), sharex=True, sharey=True)\n",
    "\n",
    "#     for idx, (name, group) in enumerate(monthly_changes_tidy.groupby([\"NAME_1\"])):\n",
    "#         row, col = divmod(idx, n_cols)\n",
    "\n",
    "#         ax = axes[row][col]\n",
    "#         sns.lineplot(x=\"month_year\", y=\"change_rate\", data=group, ax=ax)\n",
    "#         ax.set_title(name)\n",
    "#         ax.set_xticklabels(labels=group[\"month_year\"].unique(), rotation=45)\n",
    "\n",
    "#     # Remove empty subplots\n",
    "#     for idx in range(n_regions, n_rows * n_cols):\n",
    "#         row, col = divmod(idx, n_cols)\n",
    "#         axes[row][col].remove()\n",
    "\n",
    "#     # Adjust layout\n",
    "#     line_chart_matrix_fig.tight_layout()\n",
    "\n",
    "#     return line_chart_matrix_fig\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def overall_trends_line_chart(monthly_changes=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Draw the line chart for all administrative regions\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "\n",
    "#     Returns:\n",
    "#     trends_line_chart_fig (matplotlib.figure.Figure): Figure containing the line chart for all administrative regions\n",
    "#     \"\"\"\n",
    "#     # Transpose monthly_changes DataFrame\n",
    "#     transposed_changes = monthly_changes.set_index(\"NAME_1\").transpose()\n",
    "\n",
    "#     # Create line chart\n",
    "#     trends_line_chart_fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#     transposed_changes.plot(ax=ax)\n",
    "#     plt.xlabel(\"Month\")\n",
    "#     plt.ylabel(\"Change Rate\")\n",
    "#     plt.title(\"Monthly Trends of Change Rates for All Administrative Regions\")\n",
    "#     plt.legend(title=\"Regions\", labels=transposed_changes.columns, bbox_to_anchor=(1.17, 1))\n",
    "#     plt.xticks(range(len(transposed_changes.index)), transposed_changes.index, rotation=90)\n",
    "\n",
    "#     return trends_line_chart_fig\n",
    "\n",
    "# # Example usage\n",
    "# # france_gdf = load_france_shp()\n",
    "# # mobility_data = load_mobility_data()\n",
    "# # joined_data = join_data(france_gdf, mobility_data)\n",
    "# # monthly_changes = calc_monthly_changes(joined_data)\n",
    "# # trends_line_chart_fig = overall_trends_line_chart(monthly_changes)\n",
    "# # plt.show()\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from io import StringIO\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    " \n",
    "# # Load data\n",
    "# monthly_changes = calc_monthly_changes(joined_data)\n",
    "\n",
    "# # Create and save monthly change maps\n",
    "# france_map_fig = matrix_map(monthly_changes, france_gdf)\n",
    "# france_map_fig.savefig('france_monthly_change_maps.png')\n",
    "\n",
    "# # Create and save chart matrix with line charts of each administrative region\n",
    "# line_chart_matrix_fig = chart_matrix(monthly_changes)\n",
    "# line_chart_matrix_fig.savefig('chart_matrix_line_charts.png')\n",
    "\n",
    "# # Create and save overall trends line chart\n",
    "# trends_line_chart_fig = overall_trends_line_chart(monthly_changes)\n",
    "# trends_line_chart_fig.savefig('overall_trends_line_chart.png')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111a633-11ad-4501-83b0-658a81353c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data#.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_mapping_env",
   "language": "python",
   "name": "street_mapping_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
