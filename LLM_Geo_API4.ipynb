{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx\n",
    "# ! pip install dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and developer good at Python. \n",
      "Task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      "  Use Plotly to create interactive map and charts.\n",
      "1) Create a Plotly interactive map to show each country's average per capita CO2 emission between 1970 and 2020. \n",
      "2) Select the top 10 countries by total emissions between 1970 and 2020, then draw a stacked area chart using Plotly to show their annual trends between 1970 and 2020.\n",
      "3) Select the top 10 countries by average per capita emission between 1970 and 2020, then draw a line chart using Plotly to show their annual trends between 1970 and 2020.\n",
      " \n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. Steps and data (both input and output) form a graph stored in NetworkX. Disconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully name the output data node.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”: “D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessary.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Do not put the GraphML writing process as a step in the graph.\n",
      "18. Save the network into GraphML format, save it at: E:\\Research\\LLM-Geo\\interactive_visualization\\interactive_visualization.graphml \n",
      " \n",
      "Reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      "Data locations (each data is a node): 1. CO2 emission CSV file: https://github.com/GIBDUSC/test/raw/master/CO2_emission.csv. The needed columns are: 'Country' , 'Year', 'Total', and 'Per Capita'.\n",
      "2. Country boundary ESRI Shapefile: https://github.com/gladcolor/LLM-Geo/raw/develop/interactive_visualization/world_countries.zip. The country name is in the 'name' attribute. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1: population living near hazardous wastes\n",
    "\n",
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight the borders of tracts that have hazardous waste facilities.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "\n",
    "\n",
    "task_name ='Resident_at_risk_counting'\n",
    "\n",
    "\n",
    "# Case 2: mobility data retrieval and visulization\n",
    "\"\"\"\n",
    "TASK = r'''\n",
    "1) Show the monthly change rates of each administrative regions in a France map. Each month is a sub-map in a map matrix. The base of the change rate is January 2020. \n",
    "2) Draw a line chart to show the monthly change rate trends of all administrative regeions.\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "                  \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip.\" + \\\n",
    "                  \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "                  \"REST API url with parameters for mobility data access:\" + \\\n",
    "                  \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "                  \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "                  \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code, France administrative regions start with 'FRA'.\",\n",
    "                 ]\n",
    "\n",
    "\n",
    "# task_name ='France_mobility_changes_2020'\n",
    "\"\"\"\n",
    "\n",
    "# Case 3: Provider address extraction\n",
    "# TASK = r\"\"\"1) Find out the Autism service providers' addresses or location from their website. The address usually listed in the homepage, 'about' or 'contact' page. The latter two pages usually contain 'about' or 'contact' in links embedded in the homepage.\n",
    "# 2) A provider may have multiple service address. If cannot find the address, simply return an empty text, DO NOT make up fake addresses. \n",
    "# 3) You need to send webpage text ChatGPT to extract address. Use this pre-written function your designed detailed prompt to get response from ChatGPT: helper.get_LLM_reply(prompt=your_prompt_with_webpage_text, model=r\"gpt-4\",). Use this statement to extract content from the returned response: response['choices'][0]['message']['content']. Let ChatGPT reply in json format as {'address': extracted_address}.  DO NOT reuturn explaination or conversation, return the address or empty text only. \n",
    "# 4) Save the extracted addresses as \"Address\" column, together with the given 'Provider' and 'Web Site' columns. If there are multile addresses for a provider, each address is a row in the CSV file.\n",
    "# \"\"\"\n",
    "\n",
    "# DATA_LOCATIONS = [\"Autism service provider webpage file location: E:\\Research\\LLM-Geo\\Address_extraction\\ACE_providers_AGIS.csv. The 'Web Site' column is the URL, the 'Provider' column is the provider name.\",                  \n",
    "#                  ]\n",
    "\n",
    "# task_name ='Address_extraction'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Case 3: COVID-19 prevalence trend\n",
    "TASK = r'''1) Draw a line chart to show the daily accumulated COVID-19 cases in 2021 in the US, each state each line.\n",
    "2) Draw a bar chart to show the total COVID-19 deaths in each state, sorted from high to low.\n",
    "3) Draw a scatter plot to show the relationship between total cases and total deaths in 2021. Each county is an observation. Show the regression line in the scatter plot.\n",
    "For all figures and maps, use figure size (25,15).\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. This data is for daily accumulated COVID cases for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",   \n",
    "                 ]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Case 4: COVID-19 prevalence mapping (Testing, not ready yet)\n",
    "TASK = r'''1) Draw a map matrix of South Carolina counties' monthly COVID-19 infection ratio in 2021. Each month is a submap.\n",
    "2) county infection ratio = (infection of this month / county popultion).\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [r\"South Carolina county boudary, ESRI shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/COVID-19/SC_counties.zip. \",\n",
    "                  r\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",                  \n",
    "                  r\"Population data: use Python library CensusData to obtain data. \",\n",
    "                 ]\n",
    "# API_DOC_LOCATION = [(1, r'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt')] \n",
    "API_DOC_LOCATION = [(2, r'./COVID-19/CensusData_API_DOC.txt')] \n",
    "# [(Input_data_index, API_cocumentation_path)]\n",
    "\n",
    "\n",
    "# add the API documentation to DATA_LOCATION\n",
    "for idx, path in API_DOC_LOCATION:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        docs = f.readlines()\n",
    "    docs = '\\n'.join(docs)\n",
    "\n",
    "    DATA_LOCATIONS[idx] += \"The documentation is: \\n\" + docs\n",
    "\n",
    "\n",
    "# https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/Address_extraction/ACE_providers_AGIS.csv\n",
    "\n",
    "# TASK = r'''1)Retrieve the data from the REST API and plot the intra_movement column of the returned data as line chart to show the temporal trend of all states. \n",
    "# 2) plot the temporal trend of the movement for each state. Each state figure will be sub figure in the plot. The plot has 5 columns. In addition, please add a weekly smoothed line to each sub plot, and change the line color to orange.\n",
    "# 3) Using the REST API with date range from 01/01/2020 to 12/31/2020 to analyze the movement reduction rate for each state during two periods: the first period is 01/01/2020-02/29/2020, second period is 03/01/2020 to 04/30/2020. Please find out the reduction rate for each state during the two periods, and create a table to report the result with two columns: state name, reduction rate, sorted by reduction rate.\n",
    "# '''\n",
    "# '''\n",
    "# DATA_LOCATIONS = [\"REST API url with parameters for data access: http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=us_state&begin=01/01/2020&end=12/31/2020; The response is in CSV format. There are three columns in the response: place,date,intra_movement; place refers to the state name.\"\n",
    "#                  ]\n",
    "# '''\n",
    "# 3) Show the administrative region name in the map and chart.\n",
    "#\n",
    "# task_name ='COVID-19_infection_rate'\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Case 5: interactive visualization\n",
    "#Example Source: https://artificialcorner.com/insanely-fast-data-storytelling-with-chatgpt-and-python-1bddae3976f3\n",
    "\n",
    "task_name ='interactive_visualization'\n",
    "\n",
    "TASK = r''' Use Plotly to create interactive map and charts.\n",
    "1) Create a Plotly interactive map to show each country's average per capita CO2 emission between 1970 and 2020. \n",
    "2) Select the top 10 countries by total emissions between 1970 and 2020, then draw a stacked area chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "3) Select the top 10 countries by average per capita emission between 1970 and 2020, then draw a line chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"CO2 emission CSV file: https://github.com/GIBDUSC/test/raw/master/CO2_emission.csv. The needed columns are: 'Country' , 'Year', 'Total', and 'Per Capita'.\",  \n",
    "                  r\"Country boundary ESRI Shapefile: https://github.com/gladcolor/LLM-Geo/raw/develop/interactive_visualization/world_countries.zip. The country name is in the 'name' attribute.\"\n",
    "]\n",
    "\n",
    "# The map project is EPSG:3857 althought not set.\n",
    "\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# Load CO2 emission CSV file\n",
      "G.add_node(\"CO2_emission_csv_url\", node_type=\"data\", data_path=\"https://github.com/GIBDUSC/test/raw/master/CO2_emission.csv\", description=\"CO2 emission CSV file URL\")\n",
      "G.add_node(\"load_CO2_emission_csv\", node_type=\"operation\", description=\"Load CO2 emission CSV file\")\n",
      "G.add_edge(\"CO2_emission_csv_url\", \"load_CO2_emission_csv\")\n",
      "\n",
      "G.add_node(\"CO2_emission_dataframe\", node_type=\"data\", description=\"CO2 emission data in a DataFrame\")\n",
      "G.add_edge(\"load_CO2_emission_csv\", \"CO2_emission_dataframe\")\n",
      "\n",
      "# Load world countries shapefile\n",
      "G.add_node(\"world_countries_shp_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/LLM-Geo/raw/develop/interactive_visualization/world_countries.zip\", description=\"World countries shapefile URL\")\n",
      "G.add_node(\"load_world_countries_shp\", node_type=\"operation\", description=\"Load world countries shapefile\")\n",
      "G.add_edge(\"world_countries_shp_url\", \"load_world_countries_shp\")\n",
      "\n",
      "G.add_node(\"world_countries_gdf\", node_type=\"data\", description=\"World countries GeoDataFrame\")\n",
      "G.add_edge(\"load_world_countries_shp\", \"world_countries_gdf\")\n",
      "\n",
      "# Calculate average per capita CO2 emission\n",
      "G.add_node(\"calc_avg_per_capita_emission\", node_type=\"operation\", description=\"Calculate average per capita CO2 emission between 1970-2020\")\n",
      "G.add_edge(\"CO2_emission_dataframe\", \"calc_avg_per_capita_emission\")\n",
      "\n",
      "G.add_node(\"avg_per_capita_emission\", node_type=\"data\", description=\"Average per capita CO2 emission (1970-2020) for each country\")\n",
      "G.add_edge(\"calc_avg_per_capita_emission\", \"avg_per_capita_emission\")\n",
      "\n",
      "# Create Plotly interactive map\n",
      "G.add_node(\"create_plotly_map\", node_type=\"operation\", description=\"Create Plotly interactive map for average per capita CO2 emission\")\n",
      "G.add_edge(\"world_countries_gdf\", \"create_plotly_map\")\n",
      "G.add_edge(\"avg_per_capita_emission\", \"create_plotly_map\")\n",
      "\n",
      "G.add_node(\"plotly_map\", node_type=\"data\", description=\"Plotly interactive map for average per capita CO2 emission\")\n",
      "G.add_edge(\"create_plotly_map\", \"plotly_map\")\n",
      "\n",
      "# Select top 10 countries by total emissions\n",
      "G.add_node(\"select_top10_total_emissions\", node_type=\"operation\", description=\"Select top 10 countries by total CO2 emissions between 1970-2020\")\n",
      "G.add_edge(\"CO2_emission_dataframe\", \"select_top10_total_emissions\")\n",
      "\n",
      "G.add_node(\"top10_total_emissions\", node_type=\"data\", description=\"Top 10 countries by total CO2 emissions (1970-2020)\")\n",
      "G.add_edge(\"select_top10_total_emissions\", \"top10_total_emissions\")\n",
      "\n",
      "# Draw stacked area chart\n",
      "G.add_node(\"create_stacked_area_chart\", node_type=\"operation\", description=\"Create stacked area chart for top 10 countries by total emissions\")\n",
      "G.add_edge(\"top10_total_emissions\", \"create_stacked_area_chart\")\n",
      "\n",
      "G.add_node(\"stacked_area_chart\", node_type=\"data\", description=\"Stacked area chart for top 10 countries by total CO2 emissions\")\n",
      "G.add_edge(\"create_stacked_area_chart\", \"stacked_area_chart\")\n",
      "\n",
      "# Select top 10 countries by average per capita emissions\n",
      "G.add_node(\"select_top10_avg_per_capita\", node_type=\"operation\", description=\"Select top 10 countries by average per capita CO2 emissions between 1970-2020\")\n",
      "G.add_edge(\"avg_per_capita_emission\", \"select_top10_avg_per_capita\")\n",
      "\n",
      "G.add_node(\"top10_avg_per_capita\", node_type=\"data\", description=\"Top 10 countries by average per capita CO2 emissions (1970-2020)\")\n",
      "G.add_edge(\"select_top10_avg_per_capita\", \"top10_avg_per_capita\")\n",
      "\n",
      "# Draw line chart\n",
      "G.add_node(\"create_line_chart\", node_type=\"operation\", description=\"Create line chart for top 10 countries by average per capita emissions\")\n",
      "G.add_edge(\"top10_avg_per_capita\", \"create_line_chart\")\n",
      "\n",
      "G.add_node(\"line_chart\", node_type=\"data\", description=\"Line chart for top 10 countries by average per capita CO2 emissions\")\n",
      "G.add_edge(\"create_line_chart\", \"line_chart\")\n",
      "\n",
      "# Save as a GraphML file\n",
      "nx.write_graphml(G, \"E:\\\\Research\\\\LLM-Geo\\\\interactive_visualization\\\\interactive_visualization.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Research\\LLM-Geo\\interactive_visualization.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"E:\\Research\\LLM-Geo\\interactive_visualization.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a5fa22c0d0>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 8, load_CO2_emission_csv\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "2 / 8, load_world_countries_shp\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "3 / 8, calc_avg_per_capita_emission\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "4 / 8, create_plotly_map\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "5 / 8, select_top10_total_emissions\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "6 / 8, create_stacked_area_chart\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "7 / 8, select_top10_avg_per_capita\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "8 / 8, create_line_chart\n",
      "Geting LLM reply...\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "\n",
    "# all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "# print(\"All operation code: \\n\")\n",
    "# print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a4f35-689d-45c0-a66a-568868771de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "print(all_operation_code_str)\n",
    "exec(all_operation_code_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ee65-c949-497a-a491-e37eb313f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install altair\n",
    "# ! pip install panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "# print(\"Assembly code: \\n\")\n",
    "# print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebf0a5-3f14-484d-90b5-3c0b75c7b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90365390-4b0a-4164-8b25-5179d13da5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0e399-3d9f-46f8-b8a7-58d4f29b36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3834651-0f02-45f2-809f-5f8ea0615964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_mapping_env",
   "language": "python",
   "name": "street_mapping_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
