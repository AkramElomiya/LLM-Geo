{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GPU\\.conda\\envs\\Google_street_view\\lib\\site-packages\\geopandas\\_compat.py:110: UserWarning: The Shapely GEOS version (3.7.0-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf073e47-9e79-41d3-bc84-500590ad2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(DATA_LOCATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and developer good at Python. \n",
      "Task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      " 1) Draw map matrix of South Carolina counties' monthly COVID-19 infection ratio with a weekly smooth in 2021.\n",
      "2) the infection ratio = (infection of this month / county popultion).\n",
      " \n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. steps and data (both input and output) form a graph stored in NetworkX. Diconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully named the output data node.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”: “D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessery.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Do not put the GraphML writing process as a step in the graph.\n",
      "18. Save the network into GraphML format, save it at: F:\\Research\\LLM-Geo\\COVID-19_infection_rate\\COVID-19_infection_rate.graphml \n",
      " \n",
      "Reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      "Data locations (each data is a node): 1. COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01),county,state,fips,cases,deaths\n",
      "2. Population data: use Python library CensusData to obtain data. The documentation is: \n",
      "API Documentation\n",
      "\n",
      "Census Geographies\n",
      "\n",
      "class censusdata.censusgeo.censusgeo(geo, name='')\n",
      "\n",
      "Class for representing Census geographies.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "geo (tuple of 2-tuples of strings) – Tuple of 2-tuples of the form (geographic component, identifier), where geographic component is a string (e.g., ‘state’) and identifier is either a numeric code (e.g., ‘01’) or a wildcard (‘*’). These identify the geography in question.\n",
      "\n",
      "name (str, optional) – Name of geography (e.g., ‘Alabama’).\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "censusgeo([('state', '06'), ('place', '53000')], 'Oakland city, California') # Represents the Census geography for Oakland city, California.\n",
      "\n",
      "censusgeo([('state', '17'), ('county', '031')]) # Represents the Census geography for Cook County, Illinois.\n",
      "\n",
      "hierarchy()\n",
      "\n",
      "Geography hierarchy for the geographic level of this object.\n",
      "\n",
      "\n",
      "\n",
      "Returns:\tString representing the geography hierarchy (e.g., ‘state> county’).\n",
      "\n",
      "Return type:\tstr\n",
      "\n",
      "params()\n",
      "\n",
      "Geographic parameters of this object.\n",
      "\n",
      "\n",
      "\n",
      "Returns:\tTuple representing the geography hierarchy. Can be used as argument in creating new censusgeo object.\n",
      "\n",
      "Return type:\ttuple\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "g = censusdata.censusgeo([('state', '06'), ('place', '53000')])\n",
      "\n",
      "g.params() # returns (('state', '06'), ('place', '53000'))\n",
      "\n",
      "request()\n",
      "\n",
      "Generate geographic parameters for Census API request.\n",
      "\n",
      "\n",
      "\n",
      "Returns:\tDictionary with appropriate ‘for’ and, if needed, ‘in’ parameters for Census API request.\n",
      "\n",
      "Return type:\tdict\n",
      "\n",
      "sumlevel()\n",
      "\n",
      "Summary level code for the geographic level of this object.\n",
      "\n",
      "\n",
      "\n",
      "Returns:\tString representing the summary level code for this object’s geographic level, e.g., ‘050’ for ‘state> county’.\n",
      "\n",
      "Return type:\tstr\n",
      "\n",
      "Census Variables\n",
      "\n",
      "Functions for showing information about Census variables.\n",
      "\n",
      "\n",
      "\n",
      "censusdata.variable_info.censustable(src, year, table)\n",
      "\n",
      "Look up information on all variables in a table.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "src (str) – Census data source: ‘acs1’ for ACS 1-year estimates, ‘acs5’ for ACS 5-year estimates, ‘acs3’ for ACS 3-year estimates, ‘acsse’ for ACS 1-year supplemental estimates, ‘sf1’ for SF1 data.\n",
      "\n",
      "year (int) – Year of data.\n",
      "\n",
      "table (str) – Table name.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "Dictionary of variables in table, with keys ‘concept’ (overall concept the variable falls under), ‘label’ (variable label),\n",
      "\n",
      "and ‘predicateType’ (variable type).\n",
      "\n",
      "\n",
      "\n",
      "Return type:\t\n",
      "\n",
      "OrderedDict\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "censusdata.censustable('acs1', 2015, 'B23025') # Returns information on table B23025 (Employment Status for Population 16+ Years) from the ACS 2015 1-year estimates.\n",
      "\n",
      "censusdata.variable_info.censusvar(src, year, var)\n",
      "\n",
      "Download information on a list of variables from Census API.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "src (str) – Census data source: ‘acs1’ for ACS 1-year estimates, ‘acs5’ for ACS 5-year estimates, ‘acs3’ for ACS 3-year estimates, ‘acsse’ for ACS 1-year supplemental estimates, ‘sf1’ for SF1 data.\n",
      "\n",
      "year (int) – Year of data.\n",
      "\n",
      "var (list of str) – Names of Census variable.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "Dictionary with keys ‘concept’ (overall concept the variable falls under), ‘label’ (variable label),\n",
      "\n",
      "and ‘predicateType’ (variable type).\n",
      "\n",
      "\n",
      "\n",
      "Return type:\t\n",
      "\n",
      "dict\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "censusdata.censusvar('sf1', 2010, ['P001001']) # Returns information on the variable P0010001 from the 2010 Census SF1.\n",
      "\n",
      "censusdata.variable_info.printtable(table, moe=False)\n",
      "\n",
      "Pretty print information on a Census table (such as produced by censustable).\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "table (OrderedDict) – Table information from censustable.\n",
      "\n",
      "moe (bool, optional) – Display margins of error.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "None.\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "censusdata.printtable(censusdata.censustable('acs5', 2015, 'B19013'))\n",
      "\n",
      "censusdata.variable_info.search(src, year, field, criterion, tabletype='detail')\n",
      "\n",
      "Search Census variables.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "src (str) – Census data source: ‘acs1’ for ACS 1-year estimates, ‘acs5’ for ACS 5-year estimates, ‘acs3’ for ACS 3-year estimates, ‘acsse’ for ACS 1-year supplemental estimates, ‘sf1’ for SF1 data.\n",
      "\n",
      "year (int) – Year of data.\n",
      "\n",
      "field (str) – Field in which to search.\n",
      "\n",
      "criterion (str or function) – Search criterion. Either string to search for, or a function which will be passed the value of field and return True if a match and False otherwise.\n",
      "\n",
      "tabletype (str, optional) – Type of table from which variables are drawn (only applicable to ACS data). Options are ‘detail’ (detail tables), ‘subject’ (subject tables), ‘profile’ (data profile tables), ‘cprofile’ (comparison profile tables).\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "List of 3-tuples containing variable names, concepts, and labels matching the search criterion.\n",
      "\n",
      "\n",
      "\n",
      "Return type:\t\n",
      "\n",
      "list\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "# Search for ACS 2011-2015 5-year estimate variables where the concept includes the text 'unweighted sample'.\n",
      "\n",
      "censusdata.search('acs5', 2015, 'concept', 'unweighted sample')\n",
      "\n",
      "# Search for ACS 2011-2015 5-year estimate variables where the specific variable label includes the text 'unemploy'.\n",
      "\n",
      "censusdata.search('acs5', 2015, 'label', 'unemploy')\n",
      "\n",
      "# Search for ACS 2011-2015 5-year estimate variables where the concept includes the text 'unweighted sample' and the text 'housing'.\n",
      "\n",
      "censusdata.search('acs5', 2015, 'concept', lambda value: re.search('unweighted sample', value, re.IGNORECASE) and re.search('housing', value, re.IGNORECASE))\n",
      "\n",
      "Download Data\n",
      "\n",
      "Functions for downloading data and lists of geographies from the Census API.\n",
      "\n",
      "\n",
      "\n",
      "censusdata.download.download(src, year, geo, var, key=None, tabletype='detail', endpt='')\n",
      "\n",
      "Download data from Census API.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "src (str) – Census data source: ‘acs1’ for ACS 1-year estimates, ‘acs5’ for ACS 5-year estimates, ‘acs3’ for ACS 3-year estimates, ‘acsse’ for ACS 1-year supplemental estimates, ‘sf1’ for SF1 data.\n",
      "\n",
      "year (int) – Year of data.\n",
      "\n",
      "geo (censusgeo) – Geographies for which to download data.\n",
      "\n",
      "var (list of str) – Census variables to download.\n",
      "\n",
      "key (str, optional) – Census API key.\n",
      "\n",
      "tabletype (str, optional) – Type of table from which variables are drawn (only applicable to ACS data). Options are ‘detail’ (detail tables), ‘subject’ (subject tables), ‘profile’ (data profile tables), ‘cprofile’ (comparison profile tables).\n",
      "\n",
      "endpt (str, optional) – Allows override of whether old or new API endpoint is used. Specify ‘old’ for old, ‘new’ for new, ‘’ to use default. This option generally shouldn’t need to be specified but can be helpful if download problems are encountered.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "Data frame with columns corresponding to designated variables, and row index of censusgeo objects representing Census geographies.\n",
      "\n",
      "\n",
      "\n",
      "Return type:\t\n",
      "\n",
      "pandas.DataFrame\n",
      "\n",
      "\n",
      "\n",
      "Raises:\t\n",
      "\n",
      "ValueError – If unknown tabletype is specified.\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "# Download ACS 2011-2015 5-year estimates for Oakland city, California on population size, median age, and median household income.\n",
      "\n",
      "censusdata.download('acs5', 2015, censusdata.censusgeo([('state', '06'), ('place', '53000')]), ['B01001_001E', 'B01002_001E', 'B19013_001E'])\n",
      "\n",
      "censusdata.download.geographies(within, src, year, key=None, endpt='')\n",
      "\n",
      "List geographies within a given geography, e.g., counties within a state.\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "within (censusgeo) – Geography within which to list geographies.\n",
      "\n",
      "src (str) – Census data source: ‘acs1’ for ACS 1-year estimates, ‘acs5’ for ACS 5-year estimates, ‘acs3’ for ACS 3-year estimates, ‘acsse’ for ACS 1-year supplemental estimates, ‘sf1’ for SF1 data.\n",
      "\n",
      "year (int) – Year of data.\n",
      "\n",
      "key (str, optional) – Census API key.\n",
      "\n",
      "endpt (str, optional) – Allows override of whether old or new API endpoint is used. Specify ‘old’ for old, ‘new’ for new, ‘’ to use default. This option generally shouldn’t need to be specified but can be helpful if download problems are encountered.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "Dictionary with names as keys and censusgeo objects as values.\n",
      "\n",
      "\n",
      "\n",
      "Return type:\t\n",
      "\n",
      "dict\n",
      "\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "\n",
      "\n",
      "# Pull data on all state geographies from the ACS 2011-2015 5-year estimates.\n",
      "\n",
      "censusdata.geographies(censusdata.censusgeo([('state', '*')]), 'acs5', 2015)\n",
      "\n",
      "Export Data\n",
      "\n",
      "Functions to faciliate exporting data downloaded from Census API.\n",
      "\n",
      "\n",
      "\n",
      "censusdata.export.exportcsv(file, data)\n",
      "\n",
      "Export Pandas DataFrame where index is composed of censusgeo objects. Can be used with return value from download().\n",
      "\n",
      "\n",
      "\n",
      "Parameters:\t\n",
      "\n",
      "file – String or file handler for exporting data.\n",
      "\n",
      "data (pandas.DataFrame) – Data to export.\n",
      "\n",
      "Returns:\t\n",
      "\n",
      "None. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1: population living near hazardous waster\n",
    "'''\n",
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight the borders of tracts that have hazardous waste facilities.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "'''\n",
    "\n",
    "# Case 2: mobility data retrieval and visulization\n",
    "\"\"\"\n",
    "TASK = r'''\n",
    "1) Show the monthly change rates of each administrative regions in a France map. Each month is a sub-map in a map matrix. The base of the change rate is January 2020. \n",
    "2) Draw a line chart to show the monthly change rate trends of all administrative regeions.\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "                  \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip.\" + \\\n",
    "                  \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "                  \"REST API url with parameters for mobility data access:\" + \\\n",
    "                  \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "                  \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "                  \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code, France administrative regions start with 'FRA'.\",\n",
    "                 ]\n",
    "\n",
    "# Bug: \n",
    "# base_month =  \"2020-01\" # wrong: pd.to_datetime(\"2020-01\")\n",
    "# print(region_monthly[region_monthly['month_year'] == base_month])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Case 3: mobility data retrieval and visulization\n",
    "# TASK = r\"\"\"1) Find out the Autism service providers' addresses or location from their website. The address usually listed in the homepage, 'about' or 'contact' page. The latter two pages usually contain 'about' or 'contact' in links embedded in the homepage.\n",
    "# 2) A provider may have multiple service address. If cannot find the address, simply return an empty text, DO NOT make up fake addresses. \n",
    "# 3) You need to send webpage text ChatGPT to extract address. Use this pre-written function your designed detailed prompt to get response from ChatGPT: helper.get_LLM_reply(prompt=your_prompt_with_webpage_text, model=r\"gpt-4\",). Use this statement to extract content from the returned response: response['choices'][0]['message']['content']. Let ChatGPT reply in json format as {'address': extracted_address}.  DO NOT reuturn explaination or conversation, return the address or empty text only. \n",
    "# 4) Save the extracted addresses as \"Address\" column, together with the given 'Provider' and 'Web Site' columns. If there are multile addresses for a provider, each address is a row in the CSV file.\n",
    "# \"\"\"\n",
    "\n",
    "# DATA_LOCATIONS = [\"Autism service provider webpage file location: E:\\Research\\LLM-Geo\\Address_extraction\\ACE_providers_AGIS.csv. The 'Web Site' column is the URL, the 'Provider' column is the provider name.\",                  \n",
    "#                  ]\n",
    "\n",
    "# Case 4: COVID-19 prevalence \n",
    "TASK = r\"\"\"1) Draw a map matrix of South Carolina counties' monthly COVID-19 infection ratio in 2021. Each month is a submap.\n",
    "2) county infection ratio = (infection of this month / county popultion).\n",
    "\"\"\"\n",
    "\n",
    "# API_DOC_LOCATION = [(1, r'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt')] \n",
    "API_DOC_LOCATION = [(1, r'./COVID-19/CensusData_API_DOC.txt')] \n",
    "\n",
    "# [(Input_data_index, API_cocumentation_path)]\n",
    "\n",
    "DATA_LOCATIONS = [\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01),county,state,fips,cases,deaths\",                  \n",
    "                  \"Population data: use Python library CensusData to obtain data. \",\n",
    "                 ]\n",
    "\n",
    "# add the API documentation to DATA_LOCATION\n",
    "for idx, path in API_DOC_LOCATION:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        docs = f.readlines()\n",
    "    docs = '\\n'.join(docs)\n",
    "\n",
    "    DATA_LOCATIONS[idx] += \"The documentation is: \\n\" + docs\n",
    "\n",
    "\n",
    "# https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/Address_extraction/ACE_providers_AGIS.csv\n",
    "\n",
    "# TASK = r'''1)Retrieve the data from the REST API and plot the intra_movement column of the returned data as line chart to show the temporal trend of all states. \n",
    "# 2) plot the temporal trend of the movement for each state. Each state figure will be sub figure in the plot. The plot has 5 columns. In addition, please add a weekly smoothed line to each sub plot, and change the line color to orange.\n",
    "# 3) Using the REST API with date range from 01/01/2020 to 12/31/2020 to analyze the movement reduction rate for each state during two periods: the first period is 01/01/2020-02/29/2020, second period is 03/01/2020 to 04/30/2020. Please find out the reduction rate for each state during the two periods, and create a table to report the result with two columns: state name, reduction rate, sorted by reduction rate.\n",
    "# '''\n",
    "# '''\n",
    "# DATA_LOCATIONS = [\"REST API url with parameters for data access: http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=us_state&begin=01/01/2020&end=12/31/2020; The response is in CSV format. There are three columns in the response: place,date,intra_movement; place refers to the state name.\"\n",
    "#                  ]\n",
    "# '''\n",
    "# 3) Show the administrative region name in the map and chart.\n",
    "# \n",
    "# task_name ='Resident_at_risk_counting'\n",
    "# task_name ='France_mobility_changes_2020'  \n",
    "# task_name ='Address_extraction'  \n",
    "task_name ='COVID-19_infection_rate' \n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# Data Nodes\n",
      "\n",
      "G.add_node(\"covid_data_url\", node_type=\"data\", \n",
      "           data_path=\"https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv\", \n",
      "           description=\"COVID-19 data case in 2021 (county-level)\")\n",
      "\n",
      "G.add_node(\"county_population_data\", node_type=\"data\", description=\"County population data\")\n",
      "\n",
      "# Operation Nodes\n",
      "\n",
      "# Load COVID data\n",
      "G.add_node(\"load_covid_data\", node_type=\"operation\", description=\"Load COVID-19 data\")\n",
      "G.add_edge(\"covid_data_url\", \"load_covid_data\")\n",
      "\n",
      "G.add_node(\"covid_data_dataframe\", node_type=\"data\", description=\"COVID-19 data in a pandas DataFrame\")\n",
      "G.add_edge(\"load_covid_data\", \"covid_data_dataframe\")\n",
      "\n",
      "# Collect population data\n",
      "G.add_node(\"collect_population_data\", node_type=\"operation\", description=\"Collect population data for SC counties\")\n",
      "G.add_edge(\"covid_data_dataframe\", \"collect_population_data\")\n",
      "\n",
      "G.add_edge(\"collect_population_data\", \"county_population_data\")\n",
      "\n",
      "# Calculate infection rate\n",
      "G.add_node(\"calculate_infection_rate\", node_type=\"operation\", description=\"Calculate monthly infection ratio\")\n",
      "G.add_edge(\"covid_data_dataframe\", \"calculate_infection_rate\")\n",
      "G.add_edge(\"county_population_data\", \"calculate_infection_rate\")\n",
      "\n",
      "G.add_node(\"infection_rate_dataframe\", node_type=\"data\", description=\"COVID-19 monthly infection ratio DataFrame\")\n",
      "G.add_edge(\"calculate_infection_rate\", \"infection_rate_dataframe\")\n",
      "\n",
      "# Apply weekly smooth on infection rate\n",
      "G.add_node(\"apply_weekly_smooth\", node_type=\"operation\", description=\"Apply weekly smooth on infection rate\")\n",
      "G.add_edge(\"infection_rate_dataframe\", \"apply_weekly_smooth\")\n",
      "\n",
      "G.add_node(\"smoothed_infection_rate_dataframe\", node_type=\"data\", description=\"Smoothed infection rate DataFrame\")\n",
      "G.add_edge(\"apply_weekly_smooth\", \"smoothed_infection_rate_dataframe\")\n",
      "\n",
      "# Create map matrix\n",
      "G.add_node(\"create_map_matrix\", node_type=\"operation\", description=\"Create map matrix for SC county infection rate\")\n",
      "G.add_edge(\"smoothed_infection_rate_dataframe\", \"create_map_matrix\")\n",
      "\n",
      "G.add_node(\"map_matrix_output\", node_type=\"data\", description=\"Map matrix of SC county monthly COVID-19 infection ratio with weekly smooth\")\n",
      "G.add_edge(\"create_map_matrix\", \"map_matrix_output\")\n",
      "\n",
      "# Save NetworkX graph to GraphML\n",
      "nx.write_graphml(G, \"F:\\\\Research\\\\LLM-Geo\\\\COVID-19_infection_rate\\\\COVID-19_infection_rate.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Research\\LLM-Geo\\COVID-19_infection_rate.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"F:\\Research\\LLM-Geo\\COVID-19_infection_rate.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c5a886b908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italic-appearance",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# with open(r'F:\\Research\\LLM-Geo\\Resident_at_risk_counting\\Resident_at_risk_counting.pkl', 'rb') as f:\n",
    "#     solution = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5, load_covid_data\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "2 / 5, collect_population_data\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "3 / 5, calculate_infection_rate\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "4 / 5, apply_weekly_smooth\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "5 / 5, create_map_matrix\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "\n",
    "# all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "# print(\"All operation code: \\n\")\n",
    "# print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd1a4f35-689d-45c0-a66a-568868771de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "\n",
      "def load_covid_data(covid_data_url='https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv'):\n",
      "    \"\"\"\n",
      "    Description: Load COVID-19 data\n",
      "\n",
      "    Args:\n",
      "        covid_data_url (str): URL of the COVID-19 data csv file.\n",
      "\n",
      "    Returns:\n",
      "        covid_data_dataframe (pd.DataFrame): Dataframe containing COVID-19 data.\n",
      "    \"\"\"\n",
      "    covid_data_dataframe = pd.read_csv(covid_data_url)\n",
      "    return covid_data_dataframe\n",
      "import pandas as pd\n",
      "import censusdata\n",
      "from tqdm import tqdm\n",
      "\n",
      "def collect_population_data(covid_data_dataframe):\n",
      "    \"\"\"\n",
      "    Description: Collect population data for SC counties\n",
      "    \n",
      "    Args:\n",
      "        covid_data_dataframe (pd.DataFrame): Dataframe containing COVID-19 data.\n",
      "        \n",
      "    Returns:\n",
      "        county_population_data (pd.DataFrame): Dataframe containing SC county population data.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Filter South Carolina covid data\n",
      "    sc_covid_data = covid_data_dataframe[covid_data_dataframe['state'] == 'South Carolina']\n",
      "\n",
      "    # Get a list of unique county FIPS codes\n",
      "    sc_county_fips = sc_covid_data['fips'].unique()\n",
      "\n",
      "    # Download South Carolina county-level population data using Census API\n",
      "    sc_pop_data = []\n",
      "    for fips in tqdm(sc_county_fips):\n",
      "        county_geo = censusdata.censusgeo([('state', '45'), ('county', fips[2:])])\n",
      "        pop_data = censusdata.download.download(src='acs5', year=2019, geo=county_geo, var=['B01003_001E'])\n",
      "        pop_data['fips'] = fips\n",
      "        sc_pop_data.append(pop_data)\n",
      "\n",
      "    # Concatenate downloaded population data and format the dataframe\n",
      "    county_population_data = pd.concat(sc_pop_data).reset_index().drop(columns=['index'])\n",
      "    county_population_data.columns = ['population', 'fips']\n",
      "    county_population_data['fips'] = county_population_data['fips'].astype(str).str.replace('\\.0', '', regex=True)\n",
      "        \n",
      "    return county_population_data\n",
      "import pandas as pd\n",
      "\n",
      "def calculate_infection_rate(county_population_data, covid_data_dataframe):\n",
      "    \"\"\"\n",
      "    Description: Calculate monthly infection ratio.\n",
      "    \n",
      "    Args:\n",
      "        county_population_data (pd.DataFrame): Dataframe containing SC county population data.\n",
      "        covid_data_dataframe (pd.DataFrame): Dataframe containing COVID-19 data.\n",
      "        \n",
      "    Returns:\n",
      "        infection_rate_dataframe (pd.DataFrame): Dataframe containing monthly infection ratio.\n",
      "    \"\"\"\n",
      "\n",
      "    # Convert date to datetime object and extract month\n",
      "    covid_data_dataframe['date'] = pd.to_datetime(covid_data_dataframe['date'])\n",
      "    covid_data_dataframe['month'] = covid_data_dataframe['date'].dt.month\n",
      "\n",
      "    # Group by FIPS and month, and calculate the total cases for each month\n",
      "    monthly_cases = covid_data_dataframe.groupby(['fips', 'month']).agg({'cases': 'sum'}).reset_index()\n",
      "\n",
      "    # Merge monthly cases and county population data on FIPS\n",
      "    merged_data = pd.merge(monthly_cases, county_population_data, on='fips')\n",
      "\n",
      "    # Calculate infection ratio\n",
      "    merged_data['infection_ratio'] = merged_data['cases'] / merged_data['population']\n",
      "\n",
      "    # Create infection rate dataframe with required columns\n",
      "    infection_rate_dataframe = merged_data[['fips', 'month', 'infection_ratio']]\n",
      "\n",
      "    return infection_rate_dataframe\n",
      "import pandas as pd\n",
      "from scipy import signal\n",
      "\n",
      "def apply_weekly_smooth(infection_rate_dataframe):\n",
      "    \"\"\"\n",
      "    Description: Apply weekly smooth on infection rate\n",
      "    \n",
      "    Args:\n",
      "        infection_rate_dataframe (pd.DataFrame): Dataframe containing monthly infection ratios.\n",
      "        \n",
      "    Returns:\n",
      "        smoothed_infection_rate_dataframe (pd.DataFrame): Dataframe containing weekly smoothed infection ratio.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Apply 1D Gaussian filter to smooth the infection rate data\n",
      "    infection_rate_dataframe['smoothed_infection_ratio'] = infection_rate_dataframe.groupby('fips')['infection_ratio'].transform(lambda x: signal.savgol_filter(x, window_length=7, polyorder=2, mode='nearest'))\n",
      "\n",
      "    # Filter out the required columns\n",
      "    smoothed_infection_rate_dataframe = infection_rate_dataframe[['fips', 'month', 'smoothed_infection_ratio']]\n",
      "\n",
      "    return smoothed_infection_rate_dataframe\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "from tqdm import tqdm\n",
      "\n",
      "def create_map_matrix(smoothed_infection_rate_dataframe):\n",
      "    \"\"\"\n",
      "    Description: Create map matrix for SC county infection rate\n",
      "\n",
      "    Args:\n",
      "        smoothed_infection_rate_dataframe (pd.DataFrame): Dataframe containing weekly smoothed infection ratio.\n",
      "\n",
      "    Returns:\n",
      "        map_matrix_output (gpd.GeoDataFrame): GeoDataFrame containing map matrix of SC county infection rate.\n",
      "    \"\"\"\n",
      "\n",
      "    # Download South Carolina county boundaries\n",
      "    sc_county_boundary_url = \"https://opendata.arcgis.com/datasets/b34abd72720d4438b49cd3bc55525d68_0.zip\"\n",
      "    sc_counties = gpd.read_file(sc_county_boundary_url)\n",
      "\n",
      "    # Convert FIPS code to string type without leading zeros\n",
      "    sc_counties['GEOID'] = sc_counties['GEOID'].astype(str).str.replace('^0+', '', regex=True)\n",
      "\n",
      "    # Merge smoothed infection rate data with county boundaries on FIPS code\n",
      "    sc_counties_infection_rate = sc_counties.merge(smoothed_infection_rate_dataframe, left_on='GEOID', right_on='fips')\n",
      "\n",
      "    # Remove duplicates in the spatial join results\n",
      "    sc_counties_infection_rate = sc_counties_infection_rate.drop_duplicates(subset=['GEOID', 'month'])\n",
      "\n",
      "    # Create a map matrix GeoDataFrame containing required columns\n",
      "    map_matrix_output = sc_counties_infection_rate[['GEOID', 'month', 'smoothed_infection_ratio', 'geometry']]\n",
      "\n",
      "    return map_matrix_output\n"
     ]
    }
   ],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "exec(all_operation_code_str)\n",
    "print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def save_and_display_sc_county_maps(sc_county_matrix):\n",
      "    \"\"\"\n",
      "    Description: Save maps to file and display in the output\n",
      "\n",
      "    Args:\n",
      "        sc_county_matrix (gpd.GeoDataFrame): GeoDataFrame containing South Carolina county-level map matrix.\n",
      "\n",
      "    Returns:\n",
      "        None\n",
      "    \"\"\"\n",
      "    unique_months = sc_county_matrix['month'].unique()\n",
      "\n",
      "    for month in sorted(unique_months):\n",
      "        month_map = sc_county_matrix[sc_county_matrix['month'] == month]\n",
      "        fig, ax = plt.subplots(figsize=(12, 12), dpi=80)\n",
      "        month_map.plot(column='smoothed_infection_ratio', cmap=\"YlOrRd\", legend=True, ax=ax)\n",
      "\n",
      "        ax.set_title(f'Weekly Smoothed COVID-19 Infection Ratio in South Carolina Counties: Month {month}, 2021')\n",
      "        ax.set_axis_off()\n",
      "\n",
      "        plt.savefig(f'sc_infection_ratio_month_{month}.png', dpi=80)\n",
      "        plt.show()\n",
      "\n",
      "def main():\n",
      "    # Load COVID-19 data\n",
      "    covid_data = load_covid_data()\n",
      "\n",
      "    # Collect population data for South Carolina counties\n",
      "    sc_population_data = collect_population_data(covid_data)\n",
      "\n",
      "    # Calculate infection rate for each month\n",
      "    infection_rate_data = calculate_infection_rate(sc_population_data, covid_data)\n",
      "\n",
      "    # Apply weekly smooth\n",
      "    smoothed_infection_rate_data = apply_weekly_smooth(infection_rate_data)\n",
      "\n",
      "    # Generate map matrix\n",
      "    sc_county_matrix = create_map_matrix(smoothed_infection_rate_data)\n",
      "\n",
      "    # Save and display final maps\n",
      "    save_and_display_sc_county_maps(sc_county_matrix)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "# print(\"Assembly code: \\n\")\n",
    "# print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def save_and_display_sc_county_maps(sc_county_matrix):\n",
      "    \"\"\"\n",
      "    Description: Save maps to file and display in the output\n",
      "\n",
      "    Args:\n",
      "        sc_county_matrix (gpd.GeoDataFrame): GeoDataFrame containing South Carolina county-level map matrix.\n",
      "\n",
      "    Returns:\n",
      "        None\n",
      "    \"\"\"\n",
      "    unique_months = sc_county_matrix['month'].unique()\n",
      "\n",
      "    for month in sorted(unique_months):\n",
      "        month_map = sc_county_matrix[sc_county_matrix['month'] == month]\n",
      "        fig, ax = plt.subplots(figsize=(12, 12), dpi=80)\n",
      "        month_map.plot(column='smoothed_infection_ratio', cmap=\"YlOrRd\", legend=True, ax=ax)\n",
      "\n",
      "        ax.set_title(f'Weekly Smoothed COVID-19 Infection Ratio in South Carolina Counties: Month {month}, 2021')\n",
      "        ax.set_axis_off()\n",
      "\n",
      "        plt.savefig(f'sc_infection_ratio_month_{month}.png', dpi=80)\n",
      "        plt.show()\n",
      "\n",
      "def main():\n",
      "    # Load COVID-19 data\n",
      "    covid_data = load_covid_data()\n",
      "\n",
      "    # Collect population data for South Carolina counties\n",
      "    sc_population_data = collect_population_data(covid_data)\n",
      "\n",
      "    # Calculate infection rate for each month\n",
      "    infection_rate_data = calculate_infection_rate(sc_population_data, covid_data)\n",
      "\n",
      "    # Apply weekly smooth\n",
      "    smoothed_infection_rate_data = apply_weekly_smooth(infection_rate_data)\n",
      "\n",
      "    # Generate map matrix\n",
      "    sc_county_matrix = create_map_matrix(smoothed_infection_rate_data)\n",
      "\n",
      "    # Save and display final maps\n",
      "    save_and_display_sc_county_maps(sc_county_matrix)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90365390-4b0a-4164-8b25-5179d13da5a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-eecd76638657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mload_covid_data\u001b[1;34m(covid_data_url)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Google_street_view\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052ec70-cdab-4323-a909-35d48866982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad14dc-1217-4a94-8c11-166efdf5302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(provider_addresses['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0cb31-cf18-4e18-8d5a-682e5f2ee340",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd034cd6-c4d0-4d85-868a-f3acc7da0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_n_website_columns = load_ACE_providers_csv()\n",
    "raw_addresses = fetch_addresses_from_websites(provider_n_website_columns)\n",
    "address_components = extract_address_components(raw_addresses)\n",
    "output_csv = save_extracted_addresses(provider_n_website_columns, address_components)\n",
    "print(f\"Extracted addresses saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c61f4-fa4d-4456-8fc5-1759c6198ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5aac09-fb66-4d6a-978d-3be5c25d3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 2: mobility \n",
    "# import geopandas as gpd\n",
    "\n",
    "# def load_france_shp(france_shp_url=\"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip\"):\n",
    "#     \"\"\"\n",
    "#     Description: Load France administrative regions shapefile\n",
    "\n",
    "#     Args:\n",
    "#     france_shp_url (str): URL of the zipped shapefile\n",
    "\n",
    "#     Returns:\n",
    "#     france_gdf (GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "#     \"\"\"\n",
    "#     france_gdf = gpd.read_file(france_shp_url)\n",
    "#     return france_gdf\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import requests\n",
    "# from io import StringIO\n",
    "\n",
    "# def load_mobility_data(mobility_api_url=\"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020\"):\n",
    "#     \"\"\"\n",
    "#     Load COVID-19 mobility data\n",
    "\n",
    "#     mobility_api_url: REST API url for COVID-19 mobility data\n",
    "#     returns: mobility_data (dataframe): Mobility data with place, date and intra_movement values\n",
    "#     \"\"\"\n",
    "#     response = requests.get(mobility_api_url)\n",
    "#     data = StringIO(response.text)\n",
    "#     mobility_data = pd.read_csv(data)\n",
    "\n",
    "#     return mobility_data\n",
    "# def join_data(france_gdf=gpd.GeoDataFrame(), mobility_data=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Join shapefile and mobility data\n",
    "\n",
    "#     Args:\n",
    "#     france_gdf (GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "#     mobility_data (pd.DataFrame): Mobility data with place, date, and intra_movement values\n",
    "\n",
    "#     Returns:\n",
    "#     joined_data (GeoDataFrame): GeoDataFrame containing the joined shapefile and mobility data\n",
    "#     \"\"\"\n",
    "#     # Convert GID_1 column to string type without leading zeros\n",
    "#     france_gdf[\"GID_1\"] = france_gdf[\"GID_1\"].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#     # Convert place column to string type without leading zeros\n",
    "#     mobility_data[\"place\"] = mobility_data[\"place\"].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#     # Merge mobility data with shapefile based on GID_1 and place columns\n",
    "#     joined_data = france_gdf.merge(mobility_data, left_on=\"GID_1\", right_on=\"place\")\n",
    "\n",
    "#     # Remove duplicates\n",
    "#     joined_data.drop_duplicates(subset=[\"GID_1\", \"date\"], inplace=True)\n",
    "\n",
    "#     return joined_data\n",
    "# def calc_monthly_changes(joined_data=gpd.GeoDataFrame()):\n",
    "#     \"\"\"\n",
    "#     Create monthly change rates\n",
    "    \n",
    "#     Args:\n",
    "#     joined_data (gpd.GeoDataFrame): GeoDataFrame containing the joined shapefile and mobility data\n",
    "    \n",
    "#     Returns:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "#     \"\"\"\n",
    "#     # Parse dates and create a month-year column\n",
    "#     joined_data['date'] = pd.to_datetime(joined_data['date'])\n",
    "#     joined_data['month_year'] = joined_data['date'].dt.to_period('M')\n",
    "\n",
    "#     # Calculate the sum of intra_movement for each region and month-year\n",
    "#     region_monthly = joined_data.groupby(['NAME_1', 'month_year'])['intra_movement'].sum().reset_index()\n",
    "\n",
    "#     # Calculate the changes of each month based on January 2020\n",
    "#     base_month =  \"2020-01\" # pd.to_datetime(\"2020-01\")\n",
    "#     print(region_monthly[region_monthly['month_year'] == \"2020-01\"])\n",
    "#     baseline = region_monthly[region_monthly['month_year'] == base_month].set_index('NAME_1')['intra_movement']\n",
    "#     print(baseline)\n",
    "#     region_monthly['change_rate'] = region_monthly.apply(lambda row: (row['intra_movement'] - baseline[row['NAME_1']]) / baseline[row['NAME_1']], axis=1)\n",
    "\n",
    "#     # Pivot month_year as columns to create monthly_changes DataFrame\n",
    "#     monthly_changes = region_monthly.pivot(index='NAME_1', columns='month_year', values='change_rate').reset_index()\n",
    "\n",
    "#     return monthly_changes\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def matrix_map(monthly_changes=pd.DataFrame(), france_gdf=gpd.GeoDataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Create matrix of France maps\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "#     france_gdf (gpd.GeoDataFrame): GeoDataFrame containing the France administrative regions\n",
    "\n",
    "#     Returns:\n",
    "#     france_map_fig (Figure): Figure containing the matrix of France maps with monthly change rates\n",
    "#     \"\"\"\n",
    "#     # Merge monthly_changes with france_gdf\n",
    "#     france_gdf = france_gdf.merge(monthly_changes, on=\"NAME_1\")\n",
    "    \n",
    "#     # Set up plot\n",
    "#     plt.style.use('seaborn-darkgrid')\n",
    "#     france_map_fig, axs = plt.subplots(3, 4, figsize=(24, 18), sharex='col', sharey='row')\n",
    "#     france_map_fig.suptitle('Monthly change rates of each administrative region in France')\n",
    "\n",
    "#     # Iterate through columns for each month\n",
    "#     for idx, month_year in enumerate(monthly_changes.columns[1:]):\n",
    "#         row, col = divmod(idx, 4)\n",
    "        \n",
    "#         # Create subplot\n",
    "#         france_gdf.plot(column=month_year, ax=axs[row, col], legend=True, cmap='coolwarm', legend_kwds={'shrink': 0.8})\n",
    "#         axs[row, col].set_title(month_year.strftime(\"%B %Y\"))\n",
    "#         axs[row, col].set_xticks([])\n",
    "#         axs[row, col].set_yticks([])\n",
    "#         axs[row, col].set_xlabel(\"\")\n",
    "#         axs[row, col].set_ylabel(\"\")\n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "    \n",
    "#     return france_map_fig\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def chart_matrix(monthly_changes=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Create chart matrix of each administrative region's line chart\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "\n",
    "#     Returns:\n",
    "#     line_chart_matrix_fig (matplotlib.figure.Figure): Figure object containing the line chart matrix\n",
    "#     \"\"\"\n",
    "#     # Set default seaborn style\n",
    "#     sns.set()\n",
    "\n",
    "#     # Prepare monthly_changes data\n",
    "#     monthly_changes_tidy = pd.melt(monthly_changes, \n",
    "#                                    id_vars=[\"NAME_1\"], \n",
    "#                                    var_name=\"month_year\", \n",
    "#                                    value_name=\"change_rate\")\n",
    "#     monthly_changes_tidy[\"month_year\"] = monthly_changes_tidy[\"month_year\"].astype(str)\n",
    "\n",
    "#     # Calculate the number of rows and columns for the line chart matrix\n",
    "#     n_regions = len(monthly_changes[\"NAME_1\"].unique())\n",
    "#     n_cols = min(4, n_regions)\n",
    "#     n_rows = (n_regions // n_cols) + (1 if (n_regions % n_cols) else 0)\n",
    "\n",
    "#     # Create the line chart matrix\n",
    "#     line_chart_matrix_fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5), sharex=True, sharey=True)\n",
    "\n",
    "#     for idx, (name, group) in enumerate(monthly_changes_tidy.groupby([\"NAME_1\"])):\n",
    "#         row, col = divmod(idx, n_cols)\n",
    "\n",
    "#         ax = axes[row][col]\n",
    "#         sns.lineplot(x=\"month_year\", y=\"change_rate\", data=group, ax=ax)\n",
    "#         ax.set_title(name)\n",
    "#         ax.set_xticklabels(labels=group[\"month_year\"].unique(), rotation=45)\n",
    "\n",
    "#     # Remove empty subplots\n",
    "#     for idx in range(n_regions, n_rows * n_cols):\n",
    "#         row, col = divmod(idx, n_cols)\n",
    "#         axes[row][col].remove()\n",
    "\n",
    "#     # Adjust layout\n",
    "#     line_chart_matrix_fig.tight_layout()\n",
    "\n",
    "#     return line_chart_matrix_fig\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def overall_trends_line_chart(monthly_changes=pd.DataFrame()):\n",
    "#     \"\"\"\n",
    "#     Description: Draw the line chart for all administrative regions\n",
    "\n",
    "#     Args:\n",
    "#     monthly_changes (pd.DataFrame): DataFrame with monthly change rates for each administrative region\n",
    "\n",
    "#     Returns:\n",
    "#     trends_line_chart_fig (matplotlib.figure.Figure): Figure containing the line chart for all administrative regions\n",
    "#     \"\"\"\n",
    "#     # Transpose monthly_changes DataFrame\n",
    "#     transposed_changes = monthly_changes.set_index(\"NAME_1\").transpose()\n",
    "\n",
    "#     # Create line chart\n",
    "#     trends_line_chart_fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#     transposed_changes.plot(ax=ax)\n",
    "#     plt.xlabel(\"Month\")\n",
    "#     plt.ylabel(\"Change Rate\")\n",
    "#     plt.title(\"Monthly Trends of Change Rates for All Administrative Regions\")\n",
    "#     plt.legend(title=\"Regions\", labels=transposed_changes.columns, bbox_to_anchor=(1.17, 1))\n",
    "#     plt.xticks(range(len(transposed_changes.index)), transposed_changes.index, rotation=90)\n",
    "\n",
    "#     return trends_line_chart_fig\n",
    "\n",
    "# # Example usage\n",
    "# # france_gdf = load_france_shp()\n",
    "# # mobility_data = load_mobility_data()\n",
    "# # joined_data = join_data(france_gdf, mobility_data)\n",
    "# # monthly_changes = calc_monthly_changes(joined_data)\n",
    "# # trends_line_chart_fig = overall_trends_line_chart(monthly_changes)\n",
    "# # plt.show()\n",
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import requests\n",
    "# from io import StringIO\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    " \n",
    "# # Load data\n",
    "# monthly_changes = calc_monthly_changes(joined_data)\n",
    "\n",
    "# # Create and save monthly change maps\n",
    "# france_map_fig = matrix_map(monthly_changes, france_gdf)\n",
    "# france_map_fig.savefig('france_monthly_change_maps.png')\n",
    "\n",
    "# # Create and save chart matrix with line charts of each administrative region\n",
    "# line_chart_matrix_fig = chart_matrix(monthly_changes)\n",
    "# line_chart_matrix_fig.savefig('chart_matrix_line_charts.png')\n",
    "\n",
    "# # Create and save overall trends line chart\n",
    "# trends_line_chart_fig = overall_trends_line_chart(monthly_changes)\n",
    "# trends_line_chart_fig.savefig('overall_trends_line_chart.png')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111a633-11ad-4501-83b0-658a81353c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data#.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google_street_view",
   "language": "python",
   "name": "google_street_view"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
