{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx\n",
    "# ! pip install dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and developer good at Python. \n",
      "Task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      " 1) Draw a map to show the death rate (death/case) of COVID-19 among the countiguous US counties in 2020. Use the accumulated COVID-19 data of 2020.12.31 to compute the death rate.\n",
      "2) The map size is 15*10 inches.  \n",
      "3) Draw a scatter chart to show the correlation and trend line of the death rate with the senior resident rate, including the r-square and p-value.\n",
      " \n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. Steps and data (both input and output) form a graph stored in NetworkX. Disconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully name the output data node.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”: “D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessary.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Do not put the GraphML writing process as a step in the graph.\n",
      "18. Save the network into GraphML format, save it at: E:\\Research\\LLM-Geo\\COVID_death_rate\\COVID_death_rate.graphml \n",
      " \n",
      "Reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      "Data locations (each data is a node): 1. COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \n",
      "2. Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip. The county FIPS column is 'GEOID'. \n",
      "3. Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv. THe needed columns are: 'FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1: population living near hazardous wastes\n",
    "\n",
    "'''\n",
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight the borders of tracts that have hazardous waste facilities.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "\n",
    "\n",
    "task_name ='Resident_at_risk_counting'\n",
    "'''\n",
    "\n",
    "# Case 2: mobility data retrieval and visulization\n",
    "\"\"\"\n",
    "TASK = r'''\n",
    "1) Show the monthly change rates of each administrative regions in a France map. Each month is a sub-map in a map matrix. The base of the change rate is January 2020. \n",
    "2) Draw a line chart to show the monthly change rate trends of all administrative regeions.\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "                  \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip.\" + \\\n",
    "                  \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "                  \"REST API url with parameters for mobility data access:\" + \\\n",
    "                  \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "                  \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "                  \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code, France administrative regions start with 'FRA'.\",\n",
    "                 ]\n",
    "\n",
    "\n",
    "# task_name ='France_mobility_changes_2020'\n",
    "\"\"\"\n",
    "\n",
    "# Case 3: Provider address extraction\n",
    "# TASK = r\"\"\"1) Find out the Autism service providers' addresses or location from their website. The address usually listed in the homepage, 'about' or 'contact' page. The latter two pages usually contain 'about' or 'contact' in links embedded in the homepage.\n",
    "# 2) A provider may have multiple service address. If cannot find the address, simply return an empty text, DO NOT make up fake addresses. \n",
    "# 3) You need to send webpage text ChatGPT to extract address. Use this pre-written function your designed detailed prompt to get response from ChatGPT: helper.get_LLM_reply(prompt=your_prompt_with_webpage_text, model=r\"gpt-4\",). Use this statement to extract content from the returned response: response['choices'][0]['message']['content']. Let ChatGPT reply in json format as {'address': extracted_address}.  DO NOT reuturn explaination or conversation, return the address or empty text only. \n",
    "# 4) Save the extracted addresses as \"Address\" column, together with the given 'Provider' and 'Web Site' columns. If there are multile addresses for a provider, each address is a row in the CSV file.\n",
    "# \"\"\"\n",
    "\n",
    "# DATA_LOCATIONS = [\"Autism service provider webpage file location: E:\\Research\\LLM-Geo\\Address_extraction\\ACE_providers_AGIS.csv. The 'Web Site' column is the URL, the 'Provider' column is the provider name.\",                  \n",
    "#                  ]\n",
    "\n",
    "# task_name ='Address_extraction'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Case 4: COVID-19 prevalence mapping (Testing, not ready yet)\n",
    "TASK = r'''1) Draw a map matrix of South Carolina counties' monthly COVID-19 infection ratio in 2021. Each month is a submap.\n",
    "2) county infection ratio = (infection of this month / county popultion).\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [r\"South Carolina county boudary, ESRI shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/COVID-19/SC_counties.zip. \",\n",
    "                  r\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",                  \n",
    "                  r\"Population data: use Python library CensusData to obtain data. \",\n",
    "                 ]\n",
    "# API_DOC_LOCATION = [(1, r'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt')] \n",
    "API_DOC_LOCATION = [(2, r'./COVID-19/CensusData_API_DOC.txt')] \n",
    "# [(Input_data_index, API_cocumentation_path)]\n",
    "\n",
    "\n",
    "# add the API documentation to DATA_LOCATION\n",
    "for idx, path in API_DOC_LOCATION:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        docs = f.readlines()\n",
    "    docs = '\\n'.join(docs)\n",
    "\n",
    "    DATA_LOCATIONS[idx] += \"The documentation is: \\n\" + docs\n",
    "\n",
    "\n",
    "# https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/Address_extraction/ACE_providers_AGIS.csv\n",
    "\n",
    "# TASK = r'''1)Retrieve the data from the REST API and plot the intra_movement column of the returned data as line chart to show the temporal trend of all states. \n",
    "# 2) plot the temporal trend of the movement for each state. Each state figure will be sub figure in the plot. The plot has 5 columns. In addition, please add a weekly smoothed line to each sub plot, and change the line color to orange.\n",
    "# 3) Using the REST API with date range from 01/01/2020 to 12/31/2020 to analyze the movement reduction rate for each state during two periods: the first period is 01/01/2020-02/29/2020, second period is 03/01/2020 to 04/30/2020. Please find out the reduction rate for each state during the two periods, and create a table to report the result with two columns: state name, reduction rate, sorted by reduction rate.\n",
    "# '''\n",
    "# '''\n",
    "# DATA_LOCATIONS = [\"REST API url with parameters for data access: http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=us_state&begin=01/01/2020&end=12/31/2020; The response is in CSV format. There are three columns in the response: place,date,intra_movement; place refers to the state name.\"\n",
    "#                  ]\n",
    "# '''\n",
    "# 3) Show the administrative region name in the map and chart.\n",
    "#\n",
    "# task_name ='COVID-19_infection_rate'\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Case 5: interactive visualization\n",
    "#Example Source: https://artificialcorner.com/insanely-fast-data-storytelling-with-chatgpt-and-python-1bddae3976f3\n",
    "\n",
    "task_name ='interactive_visualization'\n",
    "\n",
    "TASK = r''' Use Plotly to create interactive map and charts.\n",
    "1) Create a Plotly interactive map to show each country's average per capita CO2 emission between 1970 and 2020. \n",
    "2) Select the top 10 countries by total emissions between 1970 and 2020, then draw a stacked area chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "3) Select the top 10 countries by average per capita emission between 1970 and 2020, then draw a line chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"CO2 emission CSV file: https://github.com/GIBDUSC/test/raw/master/CO2_emission.csv. The needed columns are: 'Country' , 'Year', 'Total', and 'Per Capita'.\",  \n",
    "                  r\"Country boundary ESRI Shapefile: https://github.com/gladcolor/LLM-Geo/raw/develop/interactive_visualization/world_countries.zip. The country name is in the 'name' attribute.\"\n",
    "]\n",
    "\n",
    "# The map project is EPSG:3857 althought not set.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Case 3: COVID-19 prevalence trend\n",
    "task_name ='COVID_death_rate'\n",
    "TASK = r'''1) Draw a map to show the death rate (death/case) of COVID-19 among the countiguous US counties in 2020. Use the accumulated COVID-19 data of 2020.12.31 to compute the death rate.\n",
    "2) The map size is 15*10 inches.  \n",
    "3) Draw a scatter chart to show the correlation and trend line of the death rate with the senior resident rate, including the r-square and p-value.\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",   \n",
    "                  r\"Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip. The county FIPS column is 'GEOID'. \",\n",
    "                  r\"Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv. THe needed columns are: 'FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'.\",\n",
    "                  # r\"Census data can be obtained use censusdata library. The returned pandas dataframe has a index like: Fayette County, Illinois: Summary level: 050, state:17> county:051. You need to write a function to extract county FIPS. \",\n",
    "                 ]\n",
    "\n",
    "\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "\n",
      "G = nx.DiGraph()\n",
      "\n",
      "#1 Load COVID-19 data\n",
      "G.add_node(\"covid_data_url\", node_type=\"data\", data_path=\"https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv\", description=\"Daily accumulated COVID cases and deaths in the US counties for 2020\")\n",
      "G.add_node(\"load_covid_data\", node_type=\"operation\", description=\"Load COVID-19 data from CSV\")\n",
      "G.add_edge(\"covid_data_url\", \"load_covid_data\")\n",
      "G.add_node(\"covid_dataframe\", node_type=\"data\", description=\"COVID-19 cases and deaths DataFrame\")\n",
      "G.add_edge(\"load_covid_data\", \"covid_dataframe\")\n",
      "\n",
      "#2 Load county boundary data\n",
      "G.add_node(\"county_boundary_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip\", description=\"Contiguous US county boundaries shapefile\")\n",
      "G.add_node(\"load_county_boundary\", node_type=\"operation\", description=\"Load county boundary data from ESRI shapefile\")\n",
      "G.add_edge(\"county_boundary_url\", \"load_county_boundary\")\n",
      "G.add_node(\"county_boundary_gdf\", node_type=\"data\", description=\"County boundary GeoDataFrame\")\n",
      "G.add_edge(\"load_county_boundary\", \"county_boundary_gdf\")\n",
      "\n",
      "#3 Load census data\n",
      "G.add_node(\"census_data_url\", node_type=\"data\", data_path=\"https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv\", description=\"ACS2020 Census data at county level\")\n",
      "G.add_node(\"load_census_data\", node_type=\"operation\", description=\"Load census data from CSV\")\n",
      "G.add_edge(\"census_data_url\", \"load_census_data\")\n",
      "G.add_node(\"census_dataframe\", node_type=\"data\", description=\"Census DataFrame\")\n",
      "G.add_edge(\"load_census_data\", \"census_dataframe\")\n",
      "\n",
      "#4 Compute death rate (death/case) at county level\n",
      "G.add_node(\"compute_death_rate\", node_type=\"operation\", description=\"Compute death rate at county level\")\n",
      "G.add_edge(\"covid_dataframe\", \"compute_death_rate\")\n",
      "G.add_node(\"death_rate\", node_type=\"data\", description=\"Death rate DataFrame\")\n",
      "G.add_edge(\"compute_death_rate\", \"death_rate\")\n",
      "\n",
      "#5 Compute senior resident rate at county level\n",
      "G.add_node(\"compute_senior_rate\", node_type=\"operation\", description=\"Compute senior resident rate at county level\")\n",
      "G.add_edge(\"census_dataframe\", \"compute_senior_rate\")\n",
      "G.add_node(\"senior_rate\", node_type=\"data\", description=\"Senior resident rate DataFrame\")\n",
      "G.add_edge(\"compute_senior_rate\", \"senior_rate\")\n",
      "\n",
      "#6 Join death rate dataframe with county boundary geodataframe on FIPS/GEOID\n",
      "G.add_node(\"join_death_rate_and_boundary\", node_type=\"operation\", description=\"Join death rate dataframe with county boundary geodataframe\")\n",
      "G.add_edge(\"death_rate\", \"join_death_rate_and_boundary\")\n",
      "G.add_edge(\"county_boundary_gdf\", \"join_death_rate_and_boundary\")\n",
      "G.add_node(\"county_boundary_death_rate\", node_type=\"data\", description=\"County boundary with death rate GeoDataFrame\")\n",
      "G.add_edge(\"join_death_rate_and_boundary\", \"county_boundary_death_rate\")\n",
      "\n",
      "#7 Draw map of death rate in US counties\n",
      "G.add_node(\"draw_death_rate_map\", node_type=\"operation\", description=\"Draw map to show the death rate of COVID-19 among US counties\")\n",
      "G.add_edge(\"county_boundary_death_rate\", \"draw_death_rate_map\")\n",
      "G.add_node(\"death_rate_map\", node_type=\"data\", description=\"Death rate map\")\n",
      "G.add_edge(\"draw_death_rate_map\", \"death_rate_map\")\n",
      "\n",
      "#8 Join senior rate dataframe with death rate dataframe on FIPS\n",
      "G.add_node(\"join_senior_and_death_rates\", node_type=\"operation\", description=\"Join senior rate dataframe with death rate dataframe\")\n",
      "G.add_edge(\"senior_rate\", \"join_senior_and_death_rates\")\n",
      "G.add_edge(\"death_rate\", \"join_senior_and_death_rates\")\n",
      "G.add_node(\"senior_death_rate_df\", node_type=\"data\", description=\"Death rate and senior rate DataFrame\")\n",
      "G.add_edge(\"join_senior_and_death_rates\", \"senior_death_rate_df\")\n",
      "\n",
      "#9 Draw scatter chart and trend line between death rate and senior resident rate\n",
      "G.add_node(\"draw_scatter_chart\", node_type=\"operation\", description=\"Draw scatter chart to show the correlation and trend line of death rate with senior resident rate, including the r-square and p-value\")\n",
      "G.add_edge(\"senior_death_rate_df\", \"draw_scatter_chart\")\n",
      "G.add_node(\"scatter_chart\", node_type=\"data\", description=\"Scatter chart showing correlation between death rate and senior resident rate\")\n",
      "G.add_edge(\"draw_scatter_chart\", \"scatter_chart\")\n",
      "\n",
      "# Save the created graph into GraphML format\n",
      "nx.write_graphml(G, \"E:\\\\Research\\\\LLM-Geo\\\\COVID_death_rate\\\\COVID_death_rate.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Research\\LLM-Geo\\COVID_death_rate.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"E:\\Research\\LLM-Geo\\COVID_death_rate.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13f851a8b20>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 9, load_covid_data\n",
      "Geting LLM reply...\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "\n",
    "# all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "# print(\"All operation code: \\n\")\n",
    "# print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a4f35-689d-45c0-a66a-568868771de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "print(all_operation_code_str)\n",
    "exec(all_operation_code_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ee65-c949-497a-a491-e37eb313f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install altair\n",
    "# ! pip install panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "# print(\"Assembly code: \\n\")\n",
    "# print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebf0a5-3f14-484d-90b5-3c0b75c7b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90365390-4b0a-4164-8b25-5179d13da5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0e399-3d9f-46f8-b8a7-58d4f29b36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3834651-0f02-45f2-809f-5f8ea0615964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_covid_data(us_counties_covid_data='https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv'):\n",
    "    \"\"\"\n",
    "    Description: Load COVID-19 cases and deaths data\n",
    "    \n",
    "    Args:\n",
    "        us_counties_covid_data (str): URL of the COVID-19 cases and deaths data CSV file\n",
    "        \n",
    "    Returns:\n",
    "        covid_df (DataFrame): DataFrame containing the loaded COVID-19 data\n",
    "    \"\"\"\n",
    "    covid_df = pd.read_csv(us_counties_covid_data, dtype={'fips': 'str'})\n",
    "    return covid_df\n",
    "import geopandas as gpd\n",
    "\n",
    "def load_county_boundary(us_county_boundary='https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip'):\n",
    "    \"\"\"\n",
    "    Description: Load contiguous US county boundary shapefile\n",
    "\n",
    "    Args:\n",
    "    us_county_boundary (str): URL of the county boundary shapefile\n",
    "\n",
    "    Returns:\n",
    "    county_gdf (GeoDataFrame): Geopandas GeoDataFrame containing US county boundaries\n",
    "    \"\"\"\n",
    "    county_gdf = gpd.read_file(us_county_boundary)\n",
    "    return county_gdf\n",
    "import pandas as pd\n",
    "\n",
    "def load_census_data(us_census_data='https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv'):\n",
    "    \"\"\"\n",
    "    Load US census data.\n",
    "    \n",
    "    Arguments:\n",
    "    - us_census_data: URL for the census CSV data file. Default is https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv.\n",
    "\n",
    "    Returns:\n",
    "    - census_df: Pandas DataFrame containing the required columns from the census CSV data, with FIPS column as string type.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV file while converting the FIPS column to string type without leading zeros.\n",
    "    census_df = pd.read_csv(us_census_data,\n",
    "                             dtype={'FIPS': 'str'},\n",
    "                             usecols=['FIPS', 'Total Population', 'Total Population: 65 to 74 Years',\n",
    "                                      'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'])\n",
    "\n",
    "    # Drop any rows with missing data and report the number of dropped rows\n",
    "    missing_count = census_df.isna().sum().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"Dropped {missing_count} rows with missing data.\")\n",
    "        census_df = census_df.dropna()\n",
    "\n",
    "    return census_df\n",
    "def filter_last_day_covid(covid_df):\n",
    "    \"\"\"\n",
    "    Description: Filter COVID-19 data by the last day of 2020 (2020-12-31)\n",
    "    \n",
    "    Args:\n",
    "        covid_df (DataFrame): DataFrame containing the loaded COVID-19 data\n",
    "      \n",
    "    Returns:\n",
    "        last_day_covid (DataFrame): DataFrame containing the COVID-19 data for 2020-12-31\n",
    "    \"\"\"\n",
    "    last_day_covid = covid_df[covid_df['date'] == '2020-12-31']\n",
    "    return last_day_covid\n",
    "def calculate_death_rate(last_day_covid):\n",
    "    \"\"\"\n",
    "    Description: Calculate the death rate for each county\n",
    "\n",
    "    Args:\n",
    "        last_day_covid (DataFrame): DataFrame containing the COVID-19 data for 2020-12-31\n",
    "                  \n",
    "    Returns:\n",
    "        death_rates (DataFrame): DataFrame containing the calculated death rates for each county\n",
    "    \"\"\"\n",
    "    last_day_covid['death_rate'] = last_day_covid['deaths'] / last_day_covid['cases']\n",
    "    death_rates = last_day_covid[['fips', 'death_rate']]\n",
    "    return death_rates\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def join_covid_boundary(county_gdf, death_rates):\n",
    "    \"\"\"\n",
    "    Description: Join the COVID-19 data and county boundaries using FIPS\n",
    "\n",
    "    Args:\n",
    "        county_gdf (GeoDataFrame): Geopandas GeoDataFrame containing US county boundaries\n",
    "        death_rates (DataFrame): DataFrame containing the calculated death rates for each county\n",
    "\n",
    "    Returns:\n",
    "        covid_boundary_gdf (GeoDataFrame): Geopandas GeoDataFrame containing US county boundaries with death rates\n",
    "    \"\"\"\n",
    "    # Convert the 'GEOID' column from new county boundary GeoDataFrame to string without leading zeros\n",
    "    county_gdf['GEOID'] = county_gdf['GEOID'].astype('str')\n",
    "\n",
    "    # Merge county boundaries GeoDataFrame with death_rates DataFrame on 'GEOID' and 'fips' columns\n",
    "    covid_boundary_gdf = pd.merge(county_gdf, death_rates, left_on='GEOID', right_on='fips')\n",
    "\n",
    "    # Keep only necessary columns in the merged GeoDataFrame\n",
    "    covid_boundary_gdf = covid_boundary_gdf[['GEOID', 'geometry', 'death_rate']]\n",
    "\n",
    "    return covid_boundary_gdf\n",
    "def calculate_senior_rate(county_gdf, census_df):\n",
    "    \"\"\"\n",
    "    Calculate the senior resident rate for each county.\n",
    "\n",
    "    Args:\n",
    "    county_gdf (GeoDataFrame): Geopandas GeoDataFrame containing US county boundaries\n",
    "    census_df (DataFrame): Pandas DataFrame containing the required columns from the census CSV data\n",
    "\n",
    "    Returns:\n",
    "    senior_rates (DataFrame): Pandas DataFrame containing county FIPS and calculated senior resident rate\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge the county boundary and census data based on FIPS and GEOID\n",
    "    merged_data = county_gdf.merge(census_df, left_on='GEOID', right_on='FIPS', how='inner')\n",
    "\n",
    "    # Calculate the senior resident rate\n",
    "    merged_data['Senior_Rate'] = ((merged_data['Total Population: 65 to 74 Years'] +\n",
    "                                  merged_data['Total Population: 75 to 84 Years'] +\n",
    "                                  merged_data['Total Population: 85 Years and Over']) /\n",
    "                                  merged_data['Total Population']) * 100\n",
    "\n",
    "    # Create a DataFrame containing county FIPS and the senior resident rate\n",
    "    senior_rates = merged_data[['FIPS', 'Senior_Rate']].copy()\n",
    "\n",
    "    return senior_rates\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def draw_death_rate_map(covid_boundary_gdf):\n",
    "    \"\"\"\n",
    "    Description: Draw a map to show the COVID-19 death rate among US counties\n",
    "\n",
    "    Args:\n",
    "        covid_boundary_gdf (GeoDataFrame): Geopandas GeoDataFrame containing US county boundaries with death rates\n",
    "\n",
    "    Returns:\n",
    "        death_rate_map (matplotlib.figure.Figure): Map showing the death rate in each US county\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the figure size\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "    # Set color bar size\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "    # Plot the map with COVID-19 death rate\n",
    "    death_rate_map = covid_boundary_gdf.plot(column='death_rate', ax=ax, legend=True, cax=cax,\n",
    "                                             cmap='viridis', vmin=0, vmax=0.15,\n",
    "                                             legend_kwds={'label': 'Death Rate'})\n",
    "\n",
    "    # Set map aesthetics\n",
    "    ax.set_title('COVID-19 Death Rate among US Counties (2020)')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    return death_rate_map\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "\n",
    "def create_scatter_chart(death_rates, senior_rates):\n",
    "    \"\"\"\n",
    "    Description: Create a scatter chart to show the correlation and trend line of death rate and senior resident rate\n",
    "    \n",
    "    Args:\n",
    "        death_rates (DataFrame): DataFrame containing the death rates for each county\n",
    "        senior_rates (DataFrame): DataFrame containing the senior resident rates for each county\n",
    "        \n",
    "    Returns:\n",
    "        scatter_chart (matplotlib.figure.Figure): Scatter chart with the correlation and trend line of death rate and senior resident rate\n",
    "    \"\"\"\n",
    "    merged_data = death_rates.merge(senior_rates, left_on='fips', right_on='FIPS', how='inner')\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(merged_data['Senior_Rate'], merged_data['death_rate'])\n",
    "\n",
    "    line = slope * merged_data['Senior_Rate'] + intercept\n",
    "\n",
    "    # Create the scatter chart\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    scatter_chart = sns.scatterplot(data=merged_data, x='Senior_Rate', y='death_rate', alpha=0.5)\n",
    "    plt.plot(merged_data['Senior_Rate'], line, color='red', linestyle='-')\n",
    "\n",
    "    plt.xlabel('Senior Resident Rate (%)')\n",
    "    plt.ylabel('Death Rate Ratio')\n",
    "    plt.title(f\"Correlation and Trend Line of Death Rate and Senior Resident Rate\\nR-squared = {r_value**2:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "    return scatter_chart.figure\n",
    " \n",
    "    # Load the required datasets\n",
    "covid_df = load_covid_data()\n",
    "county_gdf = load_county_boundary()\n",
    "census_df = load_census_data()\n",
    "\n",
    "# Filter COVID-19 data for the last day of 2020 (2020-12-31)\n",
    "last_day_covid = filter_last_day_covid(covid_df)\n",
    "\n",
    "# Calculate the death rate for each county\n",
    "death_rates = calculate_death_rate(last_day_covid)\n",
    "\n",
    "# Join the COVID-19 data and county boundaries using FIPS\n",
    "covid_boundary_gdf = join_covid_boundary(county_gdf, death_rates)\n",
    "\n",
    "# Calculate the senior resident rate for each county\n",
    "senior_rates = calculate_senior_rate(county_gdf, census_df)\n",
    "\n",
    "# Step 1: Draw a map to show the COVID-19 death rate among US counties\n",
    "death_rate_map = draw_death_rate_map(covid_boundary_gdf)\n",
    "# death_rate_map.savefig('death_rate_map.png', dpi=300)\n",
    "\n",
    "# Step 3: Create a scatter chart to show the correlation and trend line of death rate and senior resident rate\n",
    "scatter_chart = create_scatter_chart(death_rates, senior_rates)\n",
    "# scatter_chart.savefig('scatter_chart.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59210d55-e33c-4f4a-96e2-5574610d5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.isna().sum()#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193f3f3-019e-4565-875b-7d1deefdb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# census_data_url='https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county_cleaned.csv'\n",
    "census_data_url = r\"E:\\OneDrive_USC\\OneDrive - University of South Carolina\\Research\\Spatial_data\\ACS2021_5year_county_cleaned.csv\"\n",
    "census_dataframe = pd.read_csv(census_data_url, dtype={'GEOID': str})  # , encoding='ISO-8859-1'\n",
    "census_dataframe\n",
    "rows_with_nan = census_dataframe.isna().any(axis=1)\n",
    "rows_with_nan\n",
    "print(rows_with_nan.sum())\n",
    "census_dataframe[rows_with_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7fe0e-4536-459f-bdbb-12395f52a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  census_dataframe[rows_with_nan]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda13a27-fac6-4e0f-94c6-07e86b43c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = df.isna()\n",
    "\n",
    "# Print the row and column indices\n",
    "for column in nans.columns:\n",
    "    for idx, is_nan in enumerate(nans[column]):\n",
    "        if is_nan:\n",
    "            print(f\"NaN found in column {column}, row {idx}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343e7cc-da7c-425c-8a8f-52dffe1277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Median Household Income (In 2021 Inflation Adjusted Dollars)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccaa18-91a6-4d0d-8760-9467e9a06b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_boundary_death_senior_gdf\n",
    "# senior_rate\n",
    "# death_rate\n",
    "# covid_dataframe\n",
    "\n",
    "covid_dataframe['death_rate'] = covid_dataframe['deaths'] / covid_dataframe['cases']\n",
    "death_rate = covid_dataframe.groupby('fips')['death_rate'].last()\n",
    "\n",
    "death_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_mapping_env",
   "language": "python",
   "name": "street_mapping_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
