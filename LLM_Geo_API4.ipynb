{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx\n",
    "# ! pip install dash\n",
    "# ! pip install altair\n",
    "# ! pip install panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and developer good at Python. \n",
      "Task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      " 1) Draw a map to show the death rate (death/case) of COVID-19 among the countiguous US counties in 2020. Use the accumulated COVID-19 data of 2020.12.31 to compute the death rate.\n",
      "2) The map size is 15*10 inches, make it beautiful.  \n",
      "3) Draw a scatter chart to show the correlation and trend line between the death rate and the senior resident rate, including the r-square and p-value.\n",
      " \n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. Steps and data (both input and output) form a graph stored in NetworkX. Disconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully name the output data node.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”: “D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessary.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Do not put the GraphML writing process as a step in the graph.\n",
      "18. Save the network into GraphML format, save it at: E:\\Research\\LLM-Geo\\COVID_death_rate\\COVID_death_rate.graphml \n",
      " \n",
      "Reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      "Data locations (each data is a node): 1. COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \n",
      "2. Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip. The county FIPS column is 'GEOID'. \n",
      "3. Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv. THe needed columns are: 'FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'. Drop rows with NaN cells after loading the used columns. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1: population living near hazardous wastes\n",
    "\n",
    "'''\n",
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight the borders of tracts that have hazardous waste facilities.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "\n",
    "\n",
    "task_name ='Resident_at_risk_counting'\n",
    "'''\n",
    "\n",
    "# Case 2: mobility data retrieval and visulization\n",
    "\"\"\"\n",
    "TASK = r'''\n",
    "1) Show the monthly change rates of each administrative regions in a France map. Each month is a sub-map in a map matrix. The base of the change rate is January 2020. \n",
    "2) Draw a line chart to show the monthly change rate trends of all administrative regeions.\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "                  \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip.\" + \\\n",
    "                  \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "                  \"REST API url with parameters for mobility data access:\" + \\\n",
    "                  \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "                  \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "                  \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code, France administrative regions start with 'FRA'.\",\n",
    "                 ]\n",
    "\n",
    "\n",
    "# task_name ='France_mobility_changes_2020'\n",
    "\"\"\"\n",
    "\n",
    "# Case 3: Provider address extraction\n",
    "# TASK = r\"\"\"1) Find out the Autism service providers' addresses or location from their website. The address usually listed in the homepage, 'about' or 'contact' page. The latter two pages usually contain 'about' or 'contact' in links embedded in the homepage.\n",
    "# 2) A provider may have multiple service address. If cannot find the address, simply return an empty text, DO NOT make up fake addresses. \n",
    "# 3) You need to send webpage text ChatGPT to extract address. Use this pre-written function your designed detailed prompt to get response from ChatGPT: helper.get_LLM_reply(prompt=your_prompt_with_webpage_text, model=r\"gpt-4\",). Use this statement to extract content from the returned response: response['choices'][0]['message']['content']. Let ChatGPT reply in json format as {'address': extracted_address}.  DO NOT reuturn explaination or conversation, return the address or empty text only. \n",
    "# 4) Save the extracted addresses as \"Address\" column, together with the given 'Provider' and 'Web Site' columns. If there are multile addresses for a provider, each address is a row in the CSV file.\n",
    "# \"\"\"\n",
    "\n",
    "# DATA_LOCATIONS = [\"Autism service provider webpage file location: E:\\Research\\LLM-Geo\\Address_extraction\\ACE_providers_AGIS.csv. The 'Web Site' column is the URL, the 'Provider' column is the provider name.\",                  \n",
    "#                  ]\n",
    "\n",
    "# task_name ='Address_extraction'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Case 4: COVID-19 prevalence mapping (Testing, not ready yet)\n",
    "TASK = r'''1) Draw a map matrix of South Carolina counties' monthly COVID-19 infection ratio in 2021. Each month is a submap.\n",
    "2) county infection ratio = (infection of this month / county popultion).\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [r\"South Carolina county boudary, ESRI shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/COVID-19/SC_counties.zip. \",\n",
    "                  r\"COVID-19 data case in 2021 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2021.csv. It is a CSV file; there are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",                  \n",
    "                  r\"Population data: use Python library CensusData to obtain data. \",\n",
    "                 ]\n",
    "# API_DOC_LOCATION = [(1, r'https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/COVID-19/CensusData_API_DOC.txt')] \n",
    "API_DOC_LOCATION = [(2, r'./COVID-19/CensusData_API_DOC.txt')] \n",
    "# [(Input_data_index, API_cocumentation_path)]\n",
    "\n",
    "\n",
    "# add the API documentation to DATA_LOCATION\n",
    "for idx, path in API_DOC_LOCATION:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        docs = f.readlines()\n",
    "    docs = '\\n'.join(docs)\n",
    "\n",
    "    DATA_LOCATIONS[idx] += \"The documentation is: \\n\" + docs\n",
    "\n",
    "\n",
    "# https://raw.githubusercontent.com/gladcolor/LLM-Geo/master/Address_extraction/ACE_providers_AGIS.csv\n",
    "\n",
    "# TASK = r'''1)Retrieve the data from the REST API and plot the intra_movement column of the returned data as line chart to show the temporal trend of all states. \n",
    "# 2) plot the temporal trend of the movement for each state. Each state figure will be sub figure in the plot. The plot has 5 columns. In addition, please add a weekly smoothed line to each sub plot, and change the line color to orange.\n",
    "# 3) Using the REST API with date range from 01/01/2020 to 12/31/2020 to analyze the movement reduction rate for each state during two periods: the first period is 01/01/2020-02/29/2020, second period is 03/01/2020 to 04/30/2020. Please find out the reduction rate for each state during the two periods, and create a table to report the result with two columns: state name, reduction rate, sorted by reduction rate.\n",
    "# '''\n",
    "# '''\n",
    "# DATA_LOCATIONS = [\"REST API url with parameters for data access: http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=us_state&begin=01/01/2020&end=12/31/2020; The response is in CSV format. There are three columns in the response: place,date,intra_movement; place refers to the state name.\"\n",
    "#                  ]\n",
    "# '''\n",
    "# 3) Show the administrative region name in the map and chart.\n",
    "#\n",
    "# task_name ='COVID-19_infection_rate'\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Case 5: interactive visualization\n",
    "#Example Source: https://artificialcorner.com/insanely-fast-data-storytelling-with-chatgpt-and-python-1bddae3976f3\n",
    "\n",
    "task_name ='interactive_visualization'\n",
    "\n",
    "TASK = r''' Use Plotly to create interactive map and charts.\n",
    "1) Create a Plotly interactive map to show each country's average per capita CO2 emission between 1970 and 2020. \n",
    "2) Select the top 10 countries by total emissions between 1970 and 2020, then draw a stacked area chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "3) Select the top 10 countries by average per capita emission between 1970 and 2020, then draw a line chart using Plotly to show their annual trends between 1970 and 2020.\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"CO2 emission CSV file: https://github.com/GIBDUSC/test/raw/master/CO2_emission.csv. The needed columns are: 'Country' , 'Year', 'Total', and 'Per Capita'.\",  \n",
    "                  r\"Country boundary ESRI Shapefile: https://github.com/gladcolor/LLM-Geo/raw/develop/interactive_visualization/world_countries.zip. The country name is in the 'name' attribute.\"\n",
    "]\n",
    "\n",
    "# The map project is EPSG:3857 althought not set.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Case 3: COVID-19 prevalence trend\n",
    "task_name ='COVID_death_rate'\n",
    "TASK = r'''1) Draw a map to show the death rate (death/case) of COVID-19 among the countiguous US counties in 2020. Use the accumulated COVID-19 data of 2020.12.31 to compute the death rate.\n",
    "2) The map size is 15*10 inches, make it beautiful.  \n",
    "3) Draw a scatter chart to show the correlation and trend line between the death rate and the senior resident rate, including the r-square and p-value.\n",
    "'''\n",
    "\n",
    "DATA_LOCATIONS = [\n",
    "                  r\"COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",   \n",
    "                  r\"Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip. The county FIPS column is 'GEOID'. \",\n",
    "                  r\"Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv. THe needed columns are: 'FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'. Drop rows with NaN cells after loading the used columns.\",\n",
    "                 ]\n",
    "\n",
    "                  # r\"Census data can be obtained use censusdata library. The returned pandas dataframe has a index like: Fayette County, Illinois: Summary level: 050, state:17> county:051. You need to write a function to extract county FIPS. \",\n",
    "\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# Load COVID-19 data\n",
      "G.add_node(\"covid_data_url\", node_type=\"data\", data_path=\"https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv\", description=\"COVID-19 data for US counties\")\n",
      "G.add_node(\"load_covid_data\", node_type=\"operation\", description=\"Load COVID-19 data\")\n",
      "G.add_edge(\"covid_data_url\", \"load_covid_data\")\n",
      "G.add_node(\"covid_data\", node_type=\"data\", description=\"Loaded COVID-19 data\")\n",
      "G.add_edge(\"load_covid_data\", \"covid_data\")\n",
      "\n",
      "# Load county shapefile\n",
      "G.add_node(\"county_shp_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip\", description=\"County shapefile URL\")\n",
      "G.add_node(\"load_county_shp\", node_type=\"operation\", description=\"Load county shapefile\")\n",
      "G.add_edge(\"county_shp_url\", \"load_county_shp\")\n",
      "G.add_node(\"county_gdf2\", node_type=\"data\", description=\"Loaded county shapefile\")\n",
      "G.add_edge(\"load_county_shp\", \"county_gdf2\")\n",
      "\n",
      "# Load census data\n",
      "G.add_node(\"census_data_url\", node_type=\"data\", data_path=\"https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv\", description=\"Census data URL\")\n",
      "G.add_node(\"load_census_data\", node_type=\"operation\", description=\"Load census data\")\n",
      "G.add_edge(\"census_data_url\", \"load_census_data\")\n",
      "G.add_node(\"census_data2\", node_type=\"data\", description=\"Loaded census data\")\n",
      "G.add_edge(\"load_census_data\", \"census_data2\")\n",
      "\n",
      "# Filter COVID-19 data and calculate death rate\n",
      "G.add_node(\"compute_death_rate\", node_type=\"operation\", description=\"Compute COVID-19 death rates\")\n",
      "G.add_edge(\"covid_data\", \"compute_death_rate\")\n",
      "G.add_node(\"death_rates\", node_type=\"data\", description=\"COVID-19 death rates\")\n",
      "G.add_edge(\"compute_death_rate\", \"death_rates\")\n",
      "\n",
      "# Compute percentage of senior citizens in each county\n",
      "G.add_node(\"compute_senior_rate\", node_type=\"operation\", description=\"Compute percentage of senior citizens in each county\")\n",
      "G.add_edge(\"census_data2\", \"compute_senior_rate\")\n",
      "G.add_node(\"senior_rates\", node_type=\"data\", description=\"Percentage of senior residents\")\n",
      "G.add_edge(\"compute_senior_rate\", \"senior_rates\")\n",
      "\n",
      "# Join death rates and senior rates to county data\n",
      "G.add_node(\"join_death_senior_rates\", node_type=\"operation\", description=\"Join death rates and senior rates to county data\")\n",
      "G.add_edge(\"death_rates\", \"join_death_senior_rates\")\n",
      "G.add_edge(\"senior_rates\", \"join_death_senior_rates\")\n",
      "G.add_edge(\"county_gdf2\", \"join_death_senior_rates\")\n",
      "G.add_node(\"county_death_senior_data\", node_type=\"data\", description=\"County data with death rates and senior rates\")\n",
      "G.add_edge(\"join_death_senior_rates\", \"county_death_senior_data\")\n",
      "\n",
      "# Generate death rate map\n",
      "G.add_node(\"generate_death_rate_map\", node_type=\"operation\", description=\"Generate map of COVID-19 death rates in US counties\")\n",
      "G.add_edge(\"county_death_senior_data\", \"generate_death_rate_map\")\n",
      "G.add_node(\"death_rate_map\", node_type=\"data\", description=\"COVID-19 death rate map\")\n",
      "G.add_edge(\"generate_death_rate_map\", \"death_rate_map\")\n",
      "\n",
      "# Generate scatter plot of death rate versus senior rate\n",
      "G.add_node(\"generate_scatter_plot\", node_type=\"operation\", description=\"Generate scatter plot of death rate and senior resident rate with trend line, r-squared, and p-value\")\n",
      "G.add_edge(\"death_rates\", \"generate_scatter_plot\")\n",
      "G.add_edge(\"senior_rates\", \"generate_scatter_plot\")\n",
      "G.add_node(\"scatter_plot\", node_type=\"data\", description=\"Scatter plot of death rate vs senior resident rate\")\n",
      "G.add_edge(\"generate_scatter_plot\", \"scatter_plot\")\n",
      "\n",
      "# Save the graph in GraphML format\n",
      "nx.write_graphml(G, \"E:\\\\Research\\\\LLM-Geo\\\\COVID_death_rate\\\\COVID_death_rate.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Research\\LLM-Geo\\COVID_death_rate.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"E:\\Research\\LLM-Geo\\COVID_death_rate.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13f8a89a350>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 8, load_covid_data\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "2 / 8, load_county_shp\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "3 / 8, load_census_data\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "4 / 8, compute_death_rate\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "5 / 8, compute_senior_rate\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "6 / 8, join_death_senior_rates\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "7 / 8, generate_death_rate_map\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n",
      "8 / 8, generate_scatter_plot\n",
      "Geting LLM reply...\n",
      "Got LLM reply.\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "\n",
    "# all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "# print(\"All operation code: \\n\")\n",
    "# print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cd1a4f35-689d-45c0-a66a-568868771de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "\n",
      "def load_covid_data(covid_data_url='https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv'):\n",
      "    \"\"\"\n",
      "    Load COVID-19 data.\n",
      "    \n",
      "    Args:\n",
      "    covid_data_url (str): URL for the COVID-19 data CSV file.\n",
      "    \n",
      "    Returns:\n",
      "    covid_data (DataFrame): DataFrame containing the loaded COVID-19 data.\n",
      "    \"\"\"\n",
      "    covid_data = pd.read_csv(covid_data_url, dtype={'fips': 'str'})\n",
      "    return covid_data\n",
      "import geopandas as gpd\n",
      "\n",
      "def load_county_shp(county_shp_url='https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip'):\n",
      "    \"\"\"\n",
      "    Load county shapefile.\n",
      "\n",
      "    Args:\n",
      "    county_shp_url (str): URL of the county shapefile.\n",
      "\n",
      "    Returns:\n",
      "    county_gdf2 (GeoDataFrame): A GeoDataFrame containing the county shapefile data.\n",
      "    \"\"\"\n",
      "    county_gdf = gpd.read_file(county_shp_url)\n",
      "    county_gdf2 = county_gdf.to_crs(epsg=4326)   # Convert to WGS84 coordinate system.\n",
      "    return county_gdf2\n",
      "import pandas as pd\n",
      "\n",
      "def load_census_data(census_data_url='https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv'):\n",
      "    \"\"\"\n",
      "    Description: Load census data\n",
      "    census_data_url: Census data CSV file URL\n",
      "    \"\"\"\n",
      "    \n",
      "    # Read the CSV file\n",
      "    census_data = pd.read_csv(census_data_url, dtype={'FIPS': str})\n",
      "    \n",
      "    # Select the needed columns\n",
      "    census_data2 = census_data[['FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over']]\n",
      "    \n",
      "    # Drop rows with NaN cells\n",
      "    census_data2 = census_data2.dropna()\n",
      "    \n",
      "    return census_data2\n",
      "import pandas as pd\n",
      "\n",
      "def compute_death_rate(covid_data):\n",
      "    \"\"\"\n",
      "    Compute COVID-19 death rates.\n",
      "    \n",
      "    Args:\n",
      "    covid_data (DataFrame): A DataFrame containing the COVID-19 data.\n",
      "    \n",
      "    Returns:\n",
      "    death_rates (DataFrame): A DataFrame containing the death rates for each county.\n",
      "    \"\"\"\n",
      "    covid_data_filtered = covid_data[covid_data['date'] == '2020-12-31']\n",
      "    death_rates = covid_data_filtered[['fips', 'cases', 'deaths']].copy()\n",
      "    death_rates['death_rate'] = death_rates['deaths'] / death_rates['cases']\n",
      "    return death_rates\n",
      "def compute_senior_rate(census_data2):\n",
      "    \"\"\"\n",
      "    Description: Compute percentage of senior citizens in each county\n",
      "    \n",
      "    Input:\n",
      "        census_data2 (DataFrame): Census data frame containing FIPS and population columns for various age groups\n",
      "\n",
      "    Output:\n",
      "        senior_rates (DataFrame): Data frame containing FIPS and percentage of senior citizens in each county\n",
      "    \"\"\"\n",
      "\n",
      "    # Calculate the total senior population in each county\n",
      "    census_data2['Senior Population'] = census_data2['Total Population: 65 to 74 Years'] + \\\n",
      "                                        census_data2['Total Population: 75 to 84 Years'] + \\\n",
      "                                        census_data2['Total Population: 85 Years and Over']\n",
      "    \n",
      "    # Compute the percentage of senior citizens in each county\n",
      "    census_data2['Senior Rate'] = census_data2['Senior Population'] / census_data2['Total Population'] * 100\n",
      "\n",
      "    # Create senior_rates DataFrame containing FIPS and Senior Rate\n",
      "    senior_rates = census_data2[['FIPS', 'Senior Rate']]\n",
      "\n",
      "    # Drop rows with NaN values\n",
      "    senior_rates = senior_rates.dropna()\n",
      "\n",
      "    return senior_rates\n",
      "def join_death_senior_rates(county_gdf2, death_rates, senior_rates):\n",
      "    \"\"\"\n",
      "    Join death rates and senior rates to county data.\n",
      "\n",
      "    Args:\n",
      "    county_gdf2 (GeoDataFrame): A GeoDataFrame containing the county shapefile data.\n",
      "    death_rates (DataFrame): A DataFrame containing the death rates for each county.\n",
      "    senior_rates (DataFrame): A DataFrame containing the senior rates for each county.\n",
      "\n",
      "    Returns:\n",
      "    county_death_senior_data (GeoDataFrame): A GeoDataFrame containing the county shapefile data with death rates and senior rates joined.\n",
      "    \"\"\"\n",
      "    # Convert GEOID and fips columns to string type without leading zeros\n",
      "    county_gdf2['GEOID'] = county_gdf2['GEOID'].astype(str).str.zfill(5)\n",
      "    death_rates['fips'] = death_rates['fips'].astype(str).str.zfill(5)\n",
      "    senior_rates['FIPS'] = senior_rates['FIPS'].astype(str).str.zfill(5)\n",
      "    \n",
      "    # Join death_rates and senior_rates to county_gdf2 using common columns\n",
      "    county_death_data = county_gdf2.merge(death_rates, left_on='GEOID', right_on='fips', how='inner')\n",
      "    county_death_senior_data = county_death_data.merge(senior_rates, left_on='GEOID', right_on='FIPS', how='inner')\n",
      "    \n",
      "    return county_death_senior_data\n",
      "import matplotlib.pyplot as plt\n",
      "import geopandas as gpd\n",
      "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
      "\n",
      "def generate_death_rate_map(county_death_senior_data):\n",
      "    \"\"\"\n",
      "    Generate map of COVID-19 death rates in US counties.\n",
      "    \n",
      "    Args:\n",
      "    county_death_senior_data (GeoDataFrame): A GeoDataFrame containing the county shapefile data with death rates and senior rates joined.\n",
      "    \n",
      "    Returns:\n",
      "    death_rate_map (Figure): A map showing death rate of COVID-19 among the contiguous US counties in 2020.\n",
      "    \"\"\"\n",
      "    \n",
      "    # Set up the plot and properties\n",
      "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
      "    divider = make_axes_locatable(ax)\n",
      "    cax = divider.append_axes('right', size='5%', pad=0.1)\n",
      "    \n",
      "    # Plot county boundaries and color based on death rate\n",
      "    county_death_senior_data.plot(column='death_rate', ax=ax, cmap='YlOrRd', linewidth=0.2, edgecolor='gray', legend=True, cax=cax)\n",
      "    \n",
      "    # Set the title and axis labels\n",
      "    ax.set_title('COVID-19 Death Rates in US Counties in 2020')\n",
      "    ax.set_xticks([])\n",
      "    ax.set_yticks([])\n",
      "   \n",
      "    # Return the generated map\n",
      "    return fig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "print(all_operation_code_str)\n",
    "exec(all_operation_code_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ee65-c949-497a-a491-e37eb313f3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting LLM reply...\n"
     ]
    }
   ],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "# print(\"Assembly code: \\n\")\n",
    "# print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebf0a5-3f14-484d-90b5-3c0b75c7b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90365390-4b0a-4164-8b25-5179d13da5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0e399-3d9f-46f8-b8a7-58d4f29b36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_mapping_env",
   "language": "python",
   "name": "street_mapping_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
