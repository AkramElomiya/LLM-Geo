{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_key: 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\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "# import LLM_Geo_kernel.Solution as Solution\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration 1: Resident living with hazardous wastes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and developer good at Python. \n",
      "Task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      " 1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
      "2) Generate a map to show the spatial distribution of population at the tract level and highlight those tracts that contain at least one hazardous waste facility.\n",
      " \n",
      "Data locations (each data is a node): 1. NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\n",
      "2. NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\n",
      "3. NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'. \n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. steps and data (both input and output) form a graph stored in NetworkX. Diconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully named the output data node.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {‘name’: “County boundary”, “data_type”: “data”, “data_path”:”D:\\Test\\county.shp”,  “description”: “County boundary for the study area”}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessery.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Save the network into GraphML format, save it at: E:\\OneDrive_USC\\OneDrive - University of South Carolina\\Research\\Spatial_ChatGPT\\LLM_Geo\\Resident_at_risk_counting\\Resident_at_risk_counting.graphml \n",
      " \n",
      "Reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TASK = r\"\"\"1) Find out the total population that lives within a tract that contain hazardous waste facilities. The study area is North Carolina, US.\n",
    "2) Generate a map to show the spatial distribution of population at the tract level and highlight those tracts that contain at least one hazardous waste facility.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file location: https://github.com/gladcolor/LLM- Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip.\",\n",
    "                  \"NC tract boundary shapefile location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip. The tract id column is 'Tract'.\",\n",
    "                  \"NC tract population CSV file location: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID'.\"\n",
    "                 ]\n",
    "\n",
    "task_name ='Resident_at_risk_counting'\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "# model=r\"gpt-3.5-turbo\"\n",
    "model=r\"gpt-4\"\n",
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting reply...\n",
      "Got reply.\n",
      "\n",
      "Code to generate solution graph: \n",
      "\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "\n",
      "# 2 Load NC tract boundary shapefile\n",
      "G.add_node(\"tract_shp_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip\", description=\"NC tract boundary shapefile URL\")\n",
      "G.add_node(\"load_tract_shp\", node_type=\"operation\", description=\"Load NC tract boundary shapefile\")\n",
      "G.add_edge(\"tract_shp_url\", \"load_tract_shp\")\n",
      "G.add_node(\"tract_gdf\", node_type=\"data\", description=\"NC tract boundary GeoDataFrame\")\n",
      "G.add_edge(\"load_tract_shp\", \"tract_gdf\")\n",
      "\n",
      "# 3 Load NC tract population CSV file\n",
      "G.add_node(\"tract_pop_csv_url\", node_type=\"data\", data_path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv\", description=\"NC tract population CSV file URL\")\n",
      "G.add_node(\"load_tract_pop_csv\", node_type=\"operation\", description=\"Load NC tract population CSV file\")\n",
      "G.add_edge(\"tract_pop_csv_url\", \"load_tract_pop_csv\")\n",
      "G.add_node(\"tract_pop_df\", node_type=\"data\", description=\"NC tract population DataFrame\")\n",
      "G.add_edge(\"load_tract_pop_csv\", \"tract_pop_df\")\n",
      "\n",
      "# 4 Join the tract population to tract GeoDataFrame on GEOID\n",
      "G.add_node(\"join_pop_to_tract\", node_type=\"operation\", description=\"Join population to tract GeoDataFrame\")\n",
      "G.add_edge(\"tract_pop_df\", \"join_pop_to_tract\")\n",
      "G.add_edge(\"tract_gdf\", \"join_pop_to_tract\")\n",
      "G.add_node(\"pop_tract_gdf\", node_type=\"data\", description=\"Population joined tract GeoDataFrame\")\n",
      "G.add_edge(\"join_pop_to_tract\", \"pop_tract_gdf\")\n",
      "\n",
      "# 5 Identify tracts containing hazardous waste facilities\n",
      "G.add_node(\"find_tracts_with_haz_waste\", node_type=\"operation\", description=\"Identify tracts containing hazardous waste facilities\")\n",
      "G.add_edge(\"pop_tract_gdf\", \"find_tracts_with_haz_waste\")\n",
      "G.add_edge(\"haz_waste_gdf\", \"find_tracts_with_haz_waste\")\n",
      "G.add_node(\"tracts_with_haz_waste\", node_type=\"data\", description=\"List of tracts with hazardous waste facilities\")\n",
      "G.add_edge(\"find_tracts_with_haz_waste\", \"tracts_with_haz_waste\")\n",
      "\n",
      "# 6 Calculate total population living in tracts with hazardous waste facilities\n",
      "G.add_node(\"calc_total_pop_at_risk\", node_type=\"operation\", description=\"Calculate total population living in tracts with hazardous waste facilities\")\n",
      "G.add_edge(\"pop_tract_gdf\", \"calc_total_pop_at_risk\")\n",
      "G.add_edge(\"tracts_with_haz_waste\", \"calc_total_pop_at_risk\")\n",
      "G.add_node(\"total_pop_at_risk\", node_type=\"data\", description=\"Total population living in tracts with hazardous waste facilities\")\n",
      "G.add_edge(\"calc_total_pop_at_risk\", \"total_pop_at_risk\")\n",
      "\n",
      "# 7 Generate a map highlighting tracts with hazardous waste facilities\n",
      "G.add_node(\"generate_map\", node_type=\"operation\", description=\"Generate a map highlighting tracts with hazardous waste facilities\")\n",
      "G.add_edge(\"pop_tract_gdf\", \"generate_map\")\n",
      "G.add_edge(\"tracts_with_haz_waste\", \"generate_map\")\n",
      "G.add_node(\"map_output\", node_type=\"data\", description=\"Map of spatial distribution of population and tracts with hazardous waste facilities\")\n",
      "G.add_edge(\"generate_map\", \"map_output\")\n",
      "\n",
      "# Save the graph to GraphML format\n",
      "nx.write_graphml(G, \"E:\\OneDrive_USC\\OneDrive - University of South Carolina\\Research\\Spatial_ChatGPT\\LLM_Geo\\Resident_at_risk_counting\\Resident_at_risk_counting.graphml\")\n"
     ]
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "print()\n",
    "print(\"Code to generate solution graph: \\n\")\n",
    "print(solution.code_for_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graphto generate the solution graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\OneDrive_USC\\OneDrive - University of South Carolina\\Research\\Spatial_ChatGPT\\LLM_Geo\\Resident_at_risk_counting.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"E:\\OneDrive_USC\\OneDrive - University of South Carolina\\Research\\Spatial_ChatGPT\\LLM_Geo\\Resident_at_risk_counting.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f407112e00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 7, load_haz_waste_shp\n",
      "Geting reply...\n",
      "Got reply.\n",
      "2 / 7, load_tract_shp\n",
      "Geting reply...\n",
      "Got reply.\n",
      "3 / 7, load_tract_pop_csv\n",
      "Geting reply...\n",
      "Got reply.\n",
      "4 / 7, find_tracts_with_haz_waste\n",
      "Geting reply...\n",
      "Got reply.\n",
      "5 / 7, join_pop_to_tract\n",
      "Geting reply...\n",
      "Got reply.\n",
      "6 / 7, calc_total_pop_at_risk\n",
      "Geting reply...\n",
      "Got reply.\n",
      "7 / 7, generate_map\n",
      "Geting reply...\n",
      "Got reply.\n",
      "All operation code: \n",
      "\n",
      "import geopandas as gpd\n",
      "\n",
      "def load_haz_waste_shp(haz_waste_shp_url=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\"):\n",
      "    \"\"\"\n",
      "    Load hazardous waste facility shapefile\n",
      "    \n",
      "    Args:\n",
      "    haz_waste_shp_url: Hazardous waste facility shapefile URL\n",
      "    \n",
      "    Returns:\n",
      "    haz_waste_gdf: GeoDataFrame of hazardous waste facilities\n",
      "    \"\"\"\n",
      "\n",
      "    # Load the hazardous waste shapefile directly from the URL\n",
      "    haz_waste_gdf = gpd.read_file(haz_waste_shp_url)\n",
      "    \n",
      "    return haz_waste_gdf\n",
      "import geopandas as gpd\n",
      "\n",
      "def load_tract_shp(tract_shp_url='https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip'):\n",
      "    \"\"\"\n",
      "    Description: Load NC tract boundary shapefile\n",
      "    \n",
      "    Parameters:\n",
      "    - tract_shp_url: Tract boundary shapefile URL\n",
      "    \n",
      "    Returns:\n",
      "    - tract_gdf: Tract boundary GeoDataFrame\n",
      "    \"\"\"\n",
      "    tract_gdf = gpd.read_file(tract_shp_url)\n",
      "    return tract_gdf\n",
      "def load_tract_pop_csv(tract_pop_csv_url='https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv'):\n",
      "    \"\"\"\n",
      "    Load NC tract population CSV file\n",
      "\n",
      "    Args:\n",
      "    tract_pop_csv_url (str): Tract population CSV file URL\n",
      "\n",
      "    Returns:\n",
      "    tract_pop_df (pd.DataFrame): DataFrame containing the tract population data\n",
      "    \"\"\"\n",
      "    import pandas as pd\n",
      "\n",
      "    tract_pop_df = pd.read_csv(tract_pop_csv_url)\n",
      "    return tract_pop_df\n",
      "import geopandas as gpd\n",
      "\n",
      "def find_tracts_with_haz_waste(haz_waste_gdf, pop_tract_gdf):\n",
      "    \"\"\"\n",
      "    Identify tracts containing hazardous waste facilities\n",
      "\n",
      "    haz_waste_gdf: GeoDataFrame containing hazardous waste facility shapefile\n",
      "    pop_tract_gdf: GeoDataFrame containing NC tract boundary shapefile with population\n",
      "\n",
      "    Returns:\n",
      "    tracts_with_haz_waste: GeoDataFrame with tracts containing hazardous waste facilities\n",
      "    \"\"\"\n",
      "\n",
      "    # Convert both layers to the same projection (NAD83 / North Carolina)\n",
      "    haz_waste_gdf = haz_waste_gdf.to_crs(\"EPSG:2264\")\n",
      "    pop_tract_gdf = pop_tract_gdf.to_crs(\"EPSG:2264\")\n",
      "\n",
      "    # Perform a spatial join to identify tracts containing hazardous waste facilities\n",
      "    tracts_with_haz_waste = gpd.sjoin(pop_tract_gdf, haz_waste_gdf, how=\"inner\", op=\"intersects\")\n",
      "\n",
      "    # Remove duplicates from the resulting joined dataset\n",
      "    tracts_with_haz_waste = tracts_with_haz_waste.drop_duplicates(subset=['Tract'])\n",
      "\n",
      "    return tracts_with_haz_waste\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "\n",
      "def join_pop_to_tract(tract_gdf, tract_pop_df):\n",
      "    \"\"\"\n",
      "    Join population to tract GeoDataFrame.\n",
      "    Args:\n",
      "        tract_gdf (GeoDataFrame): Tract boundary GeoDataFrame\n",
      "        tract_pop_df (DataFrame): Tract population DataFrame\n",
      "        \n",
      "    Returns:\n",
      "        pop_tract_gdf (GeoDataFrame): Tract boundary GeoDataFrame with population information\n",
      "    \"\"\"\n",
      "\n",
      "    # Convert the \"Tract\" and \"GEOID\" columns to string without leading zeros\n",
      "    tract_gdf[\"Tract\"] = tract_gdf[\"Tract\"].astype(str).str.lstrip(\"0\")\n",
      "    tract_pop_df[\"GEOID\"] = tract_pop_df[\"GEOID\"].astype(str).str.lstrip(\"0\")\n",
      "    \n",
      "    # Merge the tract_pop_df to the tract_gdf based on the \"Tract\" and \"GEOID\" columns\n",
      "    pop_tract_gdf = tract_gdf.merge(tract_pop_df, left_on=\"Tract\", right_on=\"GEOID\", how=\"left\")\n",
      "    \n",
      "    # Remove duplicate rows (if any) by keeping the first occurrence\n",
      "    pop_tract_gdf = pop_tract_gdf.drop_duplicates(subset=\"Tract\", keep=\"first\")\n",
      "\n",
      "    # Set the CRS of the pop_tract_gdf to the same as tract_gdf (if not already the same)\n",
      "    pop_tract_gdf = pop_tract_gdf.set_crs(tract_gdf.crs)\n",
      "    \n",
      "    return pop_tract_gdf\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "\n",
      "def calc_total_pop_at_risk(pop_tract_gdf, tracts_with_haz_waste):\n",
      "    \"\"\"\n",
      "    Calculate total population living in tracts with hazardous waste facilities\n",
      "    \n",
      "    :param pop_tract_gdf: GeoDataFrame of NC tracts with population data\n",
      "    :param tracts_with_haz_waste: GeoDataFrame of NC tracts containing hazardous waste facilities\n",
      "    :return: int, total population living in tracts with hazardous waste facilities\n",
      "    \"\"\"\n",
      "    \n",
      "    # Ensure the tract IDs are strings without leading zeros for both the DataFrames\n",
      "    pop_tract_gdf['Tract'] = pop_tract_gdf['Tract'].astype(str).str.strip('0')\n",
      "    tracts_with_haz_waste['TRACTCE'] = tracts_with_haz_waste['TRACTCE'].astype(str).str.strip('0')\n",
      "    \n",
      "    # Merge population tracts with hazardous waste tracts on Tract ID\n",
      "    pop_at_risk_gdf = pop_tract_gdf.merge(tracts_with_haz_waste.drop_duplicates(subset=['TRACTCE']), left_on='Tract', right_on='TRACTCE', how='inner')\n",
      "    \n",
      "    # Calculate the total population at risk\n",
      "    total_pop_at_risk = pop_at_risk_gdf['TotalPopulation'].sum()\n",
      "    \n",
      "    return total_pop_at_risk\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "import contextily as ctx\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def generate_map(pop_tract_gdf, tracts_with_haz_waste):\n",
      "    \"\"\"\n",
      "    Description: Generate a map highlighting tracts with hazardous waste facilities\n",
      "    \n",
      "    Arguments:\n",
      "    pop_tract_gdf: GeoDataFrame containing tract polygons and population data\n",
      "    tracts_with_haz_waste: GeoSeries of tracts containing hazardous waste facilities\n",
      "    \n",
      "    Returns:\n",
      "    map_output: the generated map object\n",
      "    \"\"\"\n",
      "\n",
      "    # Make a copy of pop_tract_gdf and set the CRS\n",
      "    map_gdf = pop_tract_gdf.to_crs(epsg=3857)\n",
      "\n",
      "    # Highlight tracts with hazardous waste facilities\n",
      "    map_gdf[\"highlight\"] = False\n",
      "    map_gdf.loc[map_gdf[\"Tract\"].isin(tracts_with_haz_waste), \"highlight\"] = True\n",
      "\n",
      "    # Create map plot\n",
      "    fig, ax = plt.subplots(figsize=(12, 12))\n",
      "\n",
      "    # Plot tracts\n",
      "    map_gdf.plot(ax=ax, column=\"highlight\", cmap=\"coolwarm\", edgecolor=\"black\",\n",
      "                 linewidth=0.3, legend=True, categorical=True, alpha=0.75)\n",
      "\n",
      "    # Add basemap \n",
      "    xmin, ymin, xmax, ymax = map_gdf.total_bounds\n",
      "    ctx.add_basemap(ax, source=ctx.providers.Stamen.TonerLite, zoom=12,\n",
      "                    alpha=0.5, attribution=\"Tracts with hazardous waste facilities\")\n",
      "    ax.set_xlim(xmin, xmax)\n",
      "    ax.set_ylim(ymin, ymax)\n",
      "    \n",
      "    # Remove axis ticks and labels\n",
      "    ax.axes.xaxis.set_ticks([])\n",
      "    ax.axes.yaxis.set_ticks([])\n",
      "    ax.set_axis_off()\n",
      "\n",
      "    return plt.show()\n"
     ]
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations()\n",
    "solution.save_solution()\n",
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "print(\"All operation code: \\n\")\n",
    "print(all_operation_code_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly code: \n",
      "\n",
      "# Main Program\n",
      "\n",
      "# Step 1: Load hazardous waste facility shapefile\n",
      "haz_waste_gdf = load_haz_waste_shp()\n",
      "\n",
      "# Step 2: Load NC tract boundary shapefile\n",
      "tract_gdf = load_tract_shp()\n",
      "\n",
      "# Step 3: Load NC tract population CSV file\n",
      "tract_pop_df = load_tract_pop_csv()\n",
      "\n",
      "# Step 4: Join population to tract GeoDataFrame\n",
      "pop_tract_gdf = join_pop_to_tract(tract_gdf, tract_pop_df)\n",
      "\n",
      "# Step 5: Find tracts with hazardous waste facilities\n",
      "tracts_with_haz_waste = find_tracts_with_haz_waste(haz_waste_gdf, pop_tract_gdf)\n",
      "\n",
      "# Step 6: Calculate total population living in tracts with hazardous waste facilities\n",
      "total_pop_at_risk = calc_total_pop_at_risk(pop_tract_gdf, tracts_with_haz_waste)\n",
      "print(\"Total population living in tracts with hazardous waste facilities:\", total_pop_at_risk)\n",
      "\n",
      "# Step 7: Generate the map\n",
      "generate_map(pop_tract_gdf, tracts_with_haz_waste)\n"
     ]
    }
   ],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response()\n",
    "# solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "print(\"Assembly code: \\n\")\n",
    "print(solution.code_for_assembly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\N\\AppData\\Local\\Temp\\ipykernel_21080\\3202600107.py:3: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(all_code)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TRACTCE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TRACTCE'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m all_operation_code_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([operation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperation_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m operation \u001b[38;5;129;01min\u001b[39;00m operations])\n\u001b[0;32m      2\u001b[0m all_code \u001b[38;5;241m=\u001b[39m all_operation_code_str \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m solution\u001b[38;5;241m.\u001b[39mcode_for_assembly\n\u001b[1;32m----> 3\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:183\u001b[0m\n",
      "File \u001b[1;32m<string>:112\u001b[0m, in \u001b[0;36mcalc_total_pop_at_risk\u001b[1;34m(pop_tract_gdf, tracts_with_haz_waste)\u001b[0m\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\geopandas\\geodataframe.py:1415\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;124;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1415\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1416\u001b[0m     geo_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geometry_column_name\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result\u001b[38;5;241m.\u001b[39mdtype, GeometryDtype):\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32me:\\ProgramData\\Anaconda3\\envs\\street_mapping_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TRACTCE'"
     ]
    }
   ],
   "source": [
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "exec(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ab0eb3c-7bb1-4f61-988b-281cbfe9ee6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import geopandas as gpd\n",
      "\n",
      "def load_haz_waste_shp(haz_waste_shp_url=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\"):\n",
      "    \"\"\"\n",
      "    Load hazardous waste facility shapefile\n",
      "    \n",
      "    Args:\n",
      "    haz_waste_shp_url: Hazardous waste facility shapefile URL\n",
      "    \n",
      "    Returns:\n",
      "    haz_waste_gdf: GeoDataFrame of hazardous waste facilities\n",
      "    \"\"\"\n",
      "\n",
      "    # Load the hazardous waste shapefile directly from the URL\n",
      "    haz_waste_gdf = gpd.read_file(haz_waste_shp_url)\n",
      "    \n",
      "    return haz_waste_gdf\n",
      "import geopandas as gpd\n",
      "\n",
      "def load_tract_shp(tract_shp_url='https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_shp_37.zip'):\n",
      "    \"\"\"\n",
      "    Description: Load NC tract boundary shapefile\n",
      "    \n",
      "    Parameters:\n",
      "    - tract_shp_url: Tract boundary shapefile URL\n",
      "    \n",
      "    Returns:\n",
      "    - tract_gdf: Tract boundary GeoDataFrame\n",
      "    \"\"\"\n",
      "    tract_gdf = gpd.read_file(tract_shp_url)\n",
      "    return tract_gdf\n",
      "def load_tract_pop_csv(tract_pop_csv_url='https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv'):\n",
      "    \"\"\"\n",
      "    Load NC tract population CSV file\n",
      "\n",
      "    Args:\n",
      "    tract_pop_csv_url (str): Tract population CSV file URL\n",
      "\n",
      "    Returns:\n",
      "    tract_pop_df (pd.DataFrame): DataFrame containing the tract population data\n",
      "    \"\"\"\n",
      "    import pandas as pd\n",
      "\n",
      "    tract_pop_df = pd.read_csv(tract_pop_csv_url)\n",
      "    return tract_pop_df\n",
      "import geopandas as gpd\n",
      "\n",
      "def find_tracts_with_haz_waste(haz_waste_gdf, pop_tract_gdf):\n",
      "    \"\"\"\n",
      "    Identify tracts containing hazardous waste facilities\n",
      "\n",
      "    haz_waste_gdf: GeoDataFrame containing hazardous waste facility shapefile\n",
      "    pop_tract_gdf: GeoDataFrame containing NC tract boundary shapefile with population\n",
      "\n",
      "    Returns:\n",
      "    tracts_with_haz_waste: GeoDataFrame with tracts containing hazardous waste facilities\n",
      "    \"\"\"\n",
      "\n",
      "    # Convert both layers to the same projection (NAD83 / North Carolina)\n",
      "    haz_waste_gdf = haz_waste_gdf.to_crs(\"EPSG:2264\")\n",
      "    pop_tract_gdf = pop_tract_gdf.to_crs(\"EPSG:2264\")\n",
      "\n",
      "    # Perform a spatial join to identify tracts containing hazardous waste facilities\n",
      "    tracts_with_haz_waste = gpd.sjoin(pop_tract_gdf, haz_waste_gdf, how=\"inner\", op=\"intersects\")\n",
      "\n",
      "    # Remove duplicates from the resulting joined dataset\n",
      "    tracts_with_haz_waste = tracts_with_haz_waste.drop_duplicates(subset=['Tract'])\n",
      "\n",
      "    return tracts_with_haz_waste\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "\n",
      "def join_pop_to_tract(tract_gdf, tract_pop_df):\n",
      "    \"\"\"\n",
      "    Join population to tract GeoDataFrame.\n",
      "    Args:\n",
      "        tract_gdf (GeoDataFrame): Tract boundary GeoDataFrame\n",
      "        tract_pop_df (DataFrame): Tract population DataFrame\n",
      "        \n",
      "    Returns:\n",
      "        pop_tract_gdf (GeoDataFrame): Tract boundary GeoDataFrame with population information\n",
      "    \"\"\"\n",
      "\n",
      "    # Convert the \"Tract\" and \"GEOID\" columns to string without leading zeros\n",
      "    tract_gdf[\"Tract\"] = tract_gdf[\"Tract\"].astype(str).str.lstrip(\"0\")\n",
      "    tract_pop_df[\"GEOID\"] = tract_pop_df[\"GEOID\"].astype(str).str.lstrip(\"0\")\n",
      "    \n",
      "    # Merge the tract_pop_df to the tract_gdf based on the \"Tract\" and \"GEOID\" columns\n",
      "    pop_tract_gdf = tract_gdf.merge(tract_pop_df, left_on=\"Tract\", right_on=\"GEOID\", how=\"left\")\n",
      "    \n",
      "    # Remove duplicate rows (if any) by keeping the first occurrence\n",
      "    pop_tract_gdf = pop_tract_gdf.drop_duplicates(subset=\"Tract\", keep=\"first\")\n",
      "\n",
      "    # Set the CRS of the pop_tract_gdf to the same as tract_gdf (if not already the same)\n",
      "    pop_tract_gdf = pop_tract_gdf.set_crs(tract_gdf.crs)\n",
      "    \n",
      "    return pop_tract_gdf\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "\n",
      "def calc_total_pop_at_risk(pop_tract_gdf, tracts_with_haz_waste):\n",
      "    \"\"\"\n",
      "    Calculate total population living in tracts with hazardous waste facilities\n",
      "    \n",
      "    :param pop_tract_gdf: GeoDataFrame of NC tracts with population data\n",
      "    :param tracts_with_haz_waste: GeoDataFrame of NC tracts containing hazardous waste facilities\n",
      "    :return: int, total population living in tracts with hazardous waste facilities\n",
      "    \"\"\"\n",
      "    \n",
      "    # Ensure the tract IDs are strings without leading zeros for both the DataFrames\n",
      "    pop_tract_gdf['Tract'] = pop_tract_gdf['Tract'].astype(str).str.strip('0')\n",
      "    tracts_with_haz_waste['TRACTCE'] = tracts_with_haz_waste['TRACTCE'].astype(str).str.strip('0')\n",
      "    \n",
      "    # Merge population tracts with hazardous waste tracts on Tract ID\n",
      "    pop_at_risk_gdf = pop_tract_gdf.merge(tracts_with_haz_waste.drop_duplicates(subset=['TRACTCE']), left_on='Tract', right_on='TRACTCE', how='inner')\n",
      "    \n",
      "    # Calculate the total population at risk\n",
      "    total_pop_at_risk = pop_at_risk_gdf['TotalPopulation'].sum()\n",
      "    \n",
      "    return total_pop_at_risk\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "import contextily as ctx\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def generate_map(pop_tract_gdf, tracts_with_haz_waste):\n",
      "    \"\"\"\n",
      "    Description: Generate a map highlighting tracts with hazardous waste facilities\n",
      "    \n",
      "    Arguments:\n",
      "    pop_tract_gdf: GeoDataFrame containing tract polygons and population data\n",
      "    tracts_with_haz_waste: GeoSeries of tracts containing hazardous waste facilities\n",
      "    \n",
      "    Returns:\n",
      "    map_output: the generated map object\n",
      "    \"\"\"\n",
      "\n",
      "    # Make a copy of pop_tract_gdf and set the CRS\n",
      "    map_gdf = pop_tract_gdf.to_crs(epsg=3857)\n",
      "\n",
      "    # Highlight tracts with hazardous waste facilities\n",
      "    map_gdf[\"highlight\"] = False\n",
      "    map_gdf.loc[map_gdf[\"Tract\"].isin(tracts_with_haz_waste), \"highlight\"] = True\n",
      "\n",
      "    # Create map plot\n",
      "    fig, ax = plt.subplots(figsize=(12, 12))\n",
      "\n",
      "    # Plot tracts\n",
      "    map_gdf.plot(ax=ax, column=\"highlight\", cmap=\"coolwarm\", edgecolor=\"black\",\n",
      "                 linewidth=0.3, legend=True, categorical=True, alpha=0.75)\n",
      "\n",
      "    # Add basemap \n",
      "    xmin, ymin, xmax, ymax = map_gdf.total_bounds\n",
      "    ctx.add_basemap(ax, source=ctx.providers.Stamen.TonerLite, zoom=12,\n",
      "                    alpha=0.5, attribution=\"Tracts with hazardous waste facilities\")\n",
      "    ax.set_xlim(xmin, xmax)\n",
      "    ax.set_ylim(ymin, ymax)\n",
      "    \n",
      "    # Remove axis ticks and labels\n",
      "    ax.axes.xaxis.set_ticks([])\n",
      "    ax.axes.yaxis.set_ticks([])\n",
      "    ax.set_axis_off()\n",
      "\n",
      "    return plt.show()\n",
      "# Main Program\n",
      "\n",
      "# Step 1: Load hazardous waste facility shapefile\n",
      "haz_waste_gdf = load_haz_waste_shp()\n",
      "\n",
      "# Step 2: Load NC tract boundary shapefile\n",
      "tract_gdf = load_tract_shp()\n",
      "\n",
      "# Step 3: Load NC tract population CSV file\n",
      "tract_pop_df = load_tract_pop_csv()\n",
      "\n",
      "# Step 4: Join population to tract GeoDataFrame\n",
      "pop_tract_gdf = join_pop_to_tract(tract_gdf, tract_pop_df)\n",
      "\n",
      "# Step 5: Find tracts with hazardous waste facilities\n",
      "tracts_with_haz_waste = find_tracts_with_haz_waste(haz_waste_gdf, pop_tract_gdf)\n",
      "\n",
      "# Step 6: Calculate total population living in tracts with hazardous waste facilities\n",
      "total_pop_at_risk = calc_total_pop_at_risk(pop_tract_gdf, tracts_with_haz_waste)\n",
      "print(\"Total population living in tracts with hazardous waste facilities:\", total_pop_at_risk)\n",
      "\n",
      "# Step 7: Generate the map\n",
      "generate_map(pop_tract_gdf, tracts_with_haz_waste)\n"
     ]
    }
   ],
   "source": [
    "print(all_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_mapping_env",
   "language": "python",
   "name": "street_mapping_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
